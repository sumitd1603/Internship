{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fb83bae",
   "metadata": {},
   "source": [
    "This notebook contains answers of the Web Scraping Assignment given to me for my internship with Flip Robo Techologies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ff9fee",
   "metadata": {},
   "source": [
    "Instructions:\n",
    "\n",
    "In all the following questions, you have to use BeautifulSoup to scrape different websites and collect data as per\n",
    "the requirement of the question.\n",
    "Every answer to the question should be in form of a python function which should take URL as the parameter.\n",
    "Use Jupyter Notebooks to program, upload it on your GitHub and send the link of the Jupyter notebook to\n",
    "your SME.\n",
    "\n",
    "The deadline for the submission of the assignment is Thursday, 30-June-2022, 11:59 PM.\n",
    "\n",
    "NOTE: kindly do all the questions in one jupyter notebook and upload on your GitHub profile and share the link of the same with me using PMT message tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca6ddba",
   "metadata": {},
   "source": [
    "Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea88d473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyforest    # For importing, analysing and manipulation of Data\n",
    "import bs4         # For Webscraping\n",
    "from bs4 import BeautifulSoup    # For Webscraping by parsing the source code and to extract required data from the parsed structure\n",
    "import requests       # To get access by requesting connection establishment to website for source codes\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd65990c",
   "metadata": {},
   "source": [
    "Question 1:\n",
    "\n",
    "Write a python program to display all the header tags from wikipedia.org."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9ad072",
   "metadata": {},
   "source": [
    "A: To start with web scraping we must first check with the legality and server permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01026888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(url,url2):                          # Defining function to check whether connection can be established and permissions\n",
    "    page= requests.get(url)              # Checking for the server to be accessible of the website to be scrapped\n",
    "    print(page,\"\\n\")                     # Display result\n",
    "    \n",
    "    if page.status_code==200:                        # Condition for accessibility\n",
    "        print (\"Server is accessible for Web Scrapping\",\"\\n\",\"\\n\")\n",
    "    else:\n",
    "        print(\"Server is not accessible for Web Scrapping\",\"\\n\",\"\\n\")\n",
    "    page2=requests.get(url2)\n",
    "    permission=BeautifulSoup(page2.content)   # To parse the permissions\n",
    "    print (permission)                        # Display permissions\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b59135",
   "metadata": {},
   "source": [
    "Recalling the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0f781fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]> \n",
      "\n",
      "Server is accessible for Web Scrapping \n",
      " \n",
      "\n",
      "<html><body><p># robots.txt for http://www.wikipedia.org/ and friends\n",
      "#\n",
      "# Please note: There are a lot of pages on this site, and there are\n",
      "# some misbehaved spiders out there that go _way_ too fast. If you're\n",
      "# irresponsible, your access to the site may be blocked.\n",
      "#\n",
      "\n",
      "# Observed spamming large amounts of https://en.wikipedia.org/?curid=NNNNNN\n",
      "# and ignoring 429 ratelimit responses, claims to respect robots:\n",
      "# http://mj12bot.com/\n",
      "User-agent: MJ12bot\n",
      "Disallow: /\n",
      "\n",
      "# advertising-related bots:\n",
      "User-agent: Mediapartners-Google*\n",
      "Disallow: /\n",
      "\n",
      "# Wikipedia work bots:\n",
      "User-agent: IsraBot\n",
      "Disallow:\n",
      "\n",
      "User-agent: Orthogaffe\n",
      "Disallow:\n",
      "\n",
      "# Crawlers that are kind enough to obey, but which we'd rather not have\n",
      "# unless they're feeding search engines.\n",
      "User-agent: UbiCrawler\n",
      "Disallow: /\n",
      "\n",
      "User-agent: DOC\n",
      "Disallow: /\n",
      "\n",
      "User-agent: Zao\n",
      "Disallow: /\n",
      "\n",
      "# Some bots are known to be trouble, particularly those designed to copy\n",
      "# entire sites. Please obey robots.txt.\n",
      "User-agent: sitecheck.internetseer.com\n",
      "Disallow: /\n",
      "\n",
      "User-agent: Zealbot\n",
      "Disallow: /\n",
      "\n",
      "User-agent: MSIECrawler\n",
      "Disallow: /\n",
      "\n",
      "User-agent: SiteSnagger\n",
      "Disallow: /\n",
      "\n",
      "User-agent: WebStripper\n",
      "Disallow: /\n",
      "\n",
      "User-agent: WebCopier\n",
      "Disallow: /\n",
      "\n",
      "User-agent: Fetch\n",
      "Disallow: /\n",
      "\n",
      "User-agent: Offline Explorer\n",
      "Disallow: /\n",
      "\n",
      "User-agent: Teleport\n",
      "Disallow: /\n",
      "\n",
      "User-agent: TeleportPro\n",
      "Disallow: /\n",
      "\n",
      "User-agent: WebZIP\n",
      "Disallow: /\n",
      "\n",
      "User-agent: linko\n",
      "Disallow: /\n",
      "\n",
      "User-agent: HTTrack\n",
      "Disallow: /\n",
      "\n",
      "User-agent: Microsoft.URL.Control\n",
      "Disallow: /\n",
      "\n",
      "User-agent: Xenu\n",
      "Disallow: /\n",
      "\n",
      "User-agent: larbin\n",
      "Disallow: /\n",
      "\n",
      "User-agent: libwww\n",
      "Disallow: /\n",
      "\n",
      "User-agent: ZyBORG\n",
      "Disallow: /\n",
      "\n",
      "User-agent: Download Ninja\n",
      "Disallow: /\n",
      "\n",
      "# Misbehaving: requests much too fast:\n",
      "User-agent: fast\n",
      "Disallow: /\n",
      "\n",
      "#\n",
      "# Sorry, wget in its recursive mode is a frequent problem.\n",
      "# Please read the man page and use it properly; there is a\n",
      "# --wait option you can use to set the delay between hits,\n",
      "# for instance.\n",
      "#\n",
      "User-agent: wget\n",
      "Disallow: /\n",
      "\n",
      "#\n",
      "# The 'grub' distributed client has been *very* poorly behaved.\n",
      "#\n",
      "User-agent: grub-client\n",
      "Disallow: /\n",
      "\n",
      "#\n",
      "# Doesn't follow robots.txt anyway, but...\n",
      "#\n",
      "User-agent: k2spider\n",
      "Disallow: /\n",
      "\n",
      "#\n",
      "# Hits many times per second, not acceptable\n",
      "# http://www.nameprotect.com/botinfo.html\n",
      "User-agent: NPBot\n",
      "Disallow: /\n",
      "\n",
      "# A capture bot, downloads gazillions of pages with no public benefit\n",
      "# http://www.webreaper.net/\n",
      "User-agent: WebReaper\n",
      "Disallow: /\n",
      "\n",
      "\n",
      "#\n",
      "# Friendly, low-speed bots are welcome viewing article pages, but not\n",
      "# dynamically-generated pages please.\n",
      "#\n",
      "# Inktomi's \"Slurp\" can read a minimum delay between hits; if your\n",
      "# bot supports such a thing using the 'Crawl-delay' or another\n",
      "# instruction, please let us know.\n",
      "#\n",
      "# There is a special exception for API mobileview to allow dynamic\n",
      "# mobile web &amp; app views to load section content.\n",
      "# These views aren't HTTP-cached but use parser cache aggressively\n",
      "# and don't expose special: pages etc.\n",
      "#\n",
      "# Another exception is for REST API documentation, located at\n",
      "# /api/rest_v1/?doc.\n",
      "#\n",
      "User-agent: *\n",
      "Allow: /w/api.php?action=mobileview&amp;\n",
      "Allow: /w/load.php?\n",
      "Allow: /api/rest_v1/?doc\n",
      "Disallow: /w/\n",
      "Disallow: /api/\n",
      "Disallow: /trap/\n",
      "Disallow: /wiki/Special:\n",
      "Disallow: /wiki/Spezial:\n",
      "Disallow: /wiki/Spesial:\n",
      "Disallow: /wiki/Special%3A\n",
      "Disallow: /wiki/Spezial%3A\n",
      "Disallow: /wiki/Spesial%3A\n",
      "\n",
      "#\n",
      "# ar:\n",
      "Disallow: /wiki/%D8%AE%D8%A7%D8%B5:Search\n",
      "Disallow: /wiki/%D8%AE%D8%A7%D8%B5%3ASearch\n",
      "#\n",
      "# dewiki:\n",
      "# T6937\n",
      "# sensible deletion and meta user discussion pages:\n",
      "Disallow: /wiki/Wikipedia:L%C3%B6schkandidaten/\n",
      "Disallow: /wiki/Wikipedia:Löschkandidaten/\n",
      "Disallow: /wiki/Wikipedia:Vandalensperrung/\n",
      "Disallow: /wiki/Wikipedia:Benutzersperrung/\n",
      "Disallow: /wiki/Wikipedia:Vermittlungsausschuss/\n",
      "Disallow: /wiki/Wikipedia:Administratoren/Probleme/\n",
      "Disallow: /wiki/Wikipedia:Adminkandidaturen/\n",
      "Disallow: /wiki/Wikipedia:Qualitätssicherung/\n",
      "Disallow: /wiki/Wikipedia:Qualit%C3%A4tssicherung/\n",
      "# 4937#5\n",
      "Disallow: /wiki/Wikipedia:Vandalismusmeldung/\n",
      "Disallow: /wiki/Wikipedia:Gesperrte_Lemmata/\n",
      "Disallow: /wiki/Wikipedia:Löschprüfung/\n",
      "Disallow: /wiki/Wikipedia:L%C3%B6schprüfung/\n",
      "Disallow: /wiki/Wikipedia:Administratoren/Notizen/\n",
      "Disallow: /wiki/Wikipedia:Schiedsgericht/Anfragen/\n",
      "Disallow: /wiki/Wikipedia:L%C3%B6schpr%C3%BCfung/\n",
      "# T14111\n",
      "Disallow: /wiki/Wikipedia:Checkuser/\n",
      "Disallow: /wiki/Wikipedia_Diskussion:Checkuser/\n",
      "Disallow: /wiki/Wikipedia_Diskussion:Adminkandidaturen/\n",
      "# T15961\n",
      "Disallow: /wiki/Wikipedia:Spam-Blacklist-Log\n",
      "Disallow: /wiki/Wikipedia%3ASpam-Blacklist-Log\n",
      "Disallow: /wiki/Wikipedia_Diskussion:Spam-Blacklist-Log\n",
      "Disallow: /wiki/Wikipedia_Diskussion%3ASpam-Blacklist-Log\n",
      "#\n",
      "# enwiki:\n",
      "# Folks get annoyed when VfD discussions end up the number 1 google hit for\n",
      "# their name. See T6776\n",
      "Disallow: /wiki/Wikipedia:Articles_for_deletion/\n",
      "Disallow: /wiki/Wikipedia%3AArticles_for_deletion/\n",
      "Disallow: /wiki/Wikipedia:Votes_for_deletion/\n",
      "Disallow: /wiki/Wikipedia%3AVotes_for_deletion/\n",
      "Disallow: /wiki/Wikipedia:Pages_for_deletion/\n",
      "Disallow: /wiki/Wikipedia%3APages_for_deletion/\n",
      "Disallow: /wiki/Wikipedia:Miscellany_for_deletion/\n",
      "Disallow: /wiki/Wikipedia%3AMiscellany_for_deletion/\n",
      "Disallow: /wiki/Wikipedia:Miscellaneous_deletion/\n",
      "Disallow: /wiki/Wikipedia%3AMiscellaneous_deletion/\n",
      "Disallow: /wiki/Wikipedia:Copyright_problems\n",
      "Disallow: /wiki/Wikipedia%3ACopyright_problems\n",
      "Disallow: /wiki/Wikipedia:Protected_titles/\n",
      "Disallow: /wiki/Wikipedia%3AProtected_titles/\n",
      "# T15398\n",
      "Disallow: /wiki/Wikipedia:WikiProject_Spam/\n",
      "Disallow: /wiki/Wikipedia%3AWikiProject_Spam/\n",
      "# T16075\n",
      "Disallow: /wiki/MediaWiki:Spam-blacklist\n",
      "Disallow: /wiki/MediaWiki%3ASpam-blacklist\n",
      "Disallow: /wiki/MediaWiki_talk:Spam-blacklist\n",
      "Disallow: /wiki/MediaWiki_talk%3ASpam-blacklist\n",
      "# T13261\n",
      "Disallow: /wiki/Wikipedia:Requests_for_arbitration/\n",
      "Disallow: /wiki/Wikipedia%3ARequests_for_arbitration/\n",
      "Disallow: /wiki/Wikipedia:Requests_for_comment/\n",
      "Disallow: /wiki/Wikipedia%3ARequests_for_comment/\n",
      "Disallow: /wiki/Wikipedia:Requests_for_adminship/\n",
      "Disallow: /wiki/Wikipedia%3ARequests_for_adminship/\n",
      "# T12288\n",
      "Disallow: /wiki/Wikipedia_talk:Articles_for_deletion/\n",
      "Disallow: /wiki/Wikipedia_talk%3AArticles_for_deletion/\n",
      "Disallow: /wiki/Wikipedia_talk:Votes_for_deletion/\n",
      "Disallow: /wiki/Wikipedia_talk%3AVotes_for_deletion/\n",
      "Disallow: /wiki/Wikipedia_talk:Pages_for_deletion/\n",
      "Disallow: /wiki/Wikipedia_talk%3APages_for_deletion/\n",
      "Disallow: /wiki/Wikipedia_talk:Miscellany_for_deletion/\n",
      "Disallow: /wiki/Wikipedia_talk%3AMiscellany_for_deletion/\n",
      "Disallow: /wiki/Wikipedia_talk:Miscellaneous_deletion/\n",
      "Disallow: /wiki/Wikipedia_talk%3AMiscellaneous_deletion/\n",
      "# T16793\n",
      "Disallow: /wiki/Wikipedia:Changing_username\n",
      "Disallow: /wiki/Wikipedia%3AChanging_username\n",
      "Disallow: /wiki/Wikipedia:Changing_username/\n",
      "Disallow: /wiki/Wikipedia%3AChanging_username/\n",
      "Disallow: /wiki/Wikipedia_talk:Changing_username\n",
      "Disallow: /wiki/Wikipedia_talk%3AChanging_username\n",
      "Disallow: /wiki/Wikipedia_talk:Changing_username/\n",
      "Disallow: /wiki/Wikipedia_talk%3AChanging_username/\n",
      "#\n",
      "# eswiki:\n",
      "# T8746\n",
      "Disallow: /wiki/Wikipedia:Consultas_de_borrado/\n",
      "Disallow: /wiki/Wikipedia%3AConsultas_de_borrado/\n",
      "#\n",
      "# fiwiki:\n",
      "# T10695\n",
      "Disallow: /wiki/Wikipedia:Poistettavat_sivut\n",
      "Disallow: /wiki/K%C3%A4ytt%C3%A4j%C3%A4:\n",
      "Disallow: /wiki/Käyttäjä:\n",
      "Disallow: /wiki/Keskustelu_k%C3%A4ytt%C3%A4j%C3%A4st%C3%A4:\n",
      "Disallow: /wiki/Keskustelu_käyttäjästä:\n",
      "Disallow: /wiki/Wikipedia:Yll%C3%A4pit%C3%A4j%C3%A4t/\n",
      "Disallow: /wiki/Wikipedia:Ylläpitäjät/\n",
      "#\n",
      "# hewiki:\n",
      "Disallow: /wiki/%D7%9E%D7%99%D7%95%D7%97%D7%93:Search\n",
      "Disallow: /wiki/%D7%9E%D7%99%D7%95%D7%97%D7%93%3ASearch\n",
      "#T11517\n",
      "Disallow: /wiki/ויקיפדיה:רשימת_מועמדים_למחיקה/\n",
      "Disallow: /wiki/ויקיפדיה%3Aרשימת_מועמדים_למחיקה/\n",
      "Disallow: /wiki/%D7%95%D7%99%D7%A7%D7%99%D7%A4%D7%93%D7%99%D7%94:%D7%A8%D7%A9%D7%99%D7%9E%D7%AA_%D7%9E%D7%95%D7%A2%D7%9E%D7%93%D7%99%D7%9D_%D7%9C%D7%9E%D7%97%D7%99%D7%A7%D7%94/\n",
      "Disallow: /wiki/%D7%95%D7%99%D7%A7%D7%99%D7%A4%D7%93%D7%99%D7%94%3A%D7%A8%D7%A9%D7%99%D7%9E%D7%AA_%D7%9E%D7%95%D7%A2%D7%9E%D7%93%D7%99%D7%9D_%D7%9C%D7%9E%D7%97%D7%99%D7%A7%D7%94/\n",
      "Disallow: /wiki/ויקיפדיה:ערכים_לא_קיימים_ומוגנים\n",
      "Disallow: /wiki/ויקיפדיה%3Aערכים_לא_קיימים_ומוגנים\n",
      "Disallow: /wiki/%D7%95%D7%99%D7%A7%D7%99%D7%A4%D7%93%D7%99%D7%94:%D7%A2%D7%A8%D7%9B%D7%99%D7%9D_%D7%9C%D7%90_%D7%A7%D7%99%D7%99%D7%9E%D7%99%D7%9D_%D7%95%D7%9E%D7%95%D7%92%D7%A0%D7%99%D7%9D\n",
      "Disallow: /wiki/%D7%95%D7%99%D7%A7%D7%99%D7%A4%D7%93%D7%99%D7%94%3A%D7%A2%D7%A8%D7%9B%D7%99%D7%9D_%D7%9C%D7%90_%D7%A7%D7%99%D7%99%D7%9E%D7%99%D7%9D_%D7%95%D7%9E%D7%95%D7%92%D7%A0%D7%99%D7%9D\n",
      "Disallow: /wiki/ויקיפדיה:דפים_לא_קיימים_ומוגנים\n",
      "Disallow: /wiki/ויקיפדיה%3Aדפים_לא_קיימים_ומוגנים\n",
      "Disallow: /wiki/%D7%95%D7%99%D7%A7%D7%99%D7%A4%D7%93%D7%99%D7%94:%D7%93%D7%A4%D7%99%D7%9D_%D7%9C%D7%90_%D7%A7%D7%99%D7%99%D7%9E%D7%99%D7%9D_%D7%95%D7%9E%D7%95%D7%92%D7%A0%D7%99%D7%9D\n",
      "Disallow: /wiki/%D7%95%D7%99%D7%A7%D7%99%D7%A4%D7%93%D7%99%D7%94%3A%D7%93%D7%A4%D7%99%D7%9D_%D7%9C%D7%90_%D7%A7%D7%99%D7%99%D7%9E%D7%99%D7%9D_%D7%95%D7%9E%D7%95%D7%92%D7%A0%D7%99%D7%9D\n",
      "#\n",
      "# huwiki:\n",
      "Disallow: /wiki/Speci%C3%A1lis:Search\n",
      "Disallow: /wiki/Speci%C3%A1lis%3ASearch\n",
      "#\n",
      "# itwiki:\n",
      "# T7545\n",
      "Disallow: /wiki/Wikipedia:Pagine_da_cancellare\n",
      "Disallow: /wiki/Wikipedia%3APagine_da_cancellare\n",
      "Disallow: /wiki/Wikipedia:Utenti_problematici\n",
      "Disallow: /wiki/Wikipedia%3AUtenti_problematici\n",
      "Disallow: /wiki/Wikipedia:Vandalismi_in_corso\n",
      "Disallow: /wiki/Wikipedia%3AVandalismi_in_corso\n",
      "Disallow: /wiki/Wikipedia:Amministratori\n",
      "Disallow: /wiki/Wikipedia%3AAmministratori\n",
      "Disallow: /wiki/Wikipedia:Proposte_di_cancellazione_semplificata\n",
      "Disallow: /wiki/Wikipedia%3AProposte_di_cancellazione_semplificata\n",
      "Disallow: /wiki/Categoria:Da_cancellare_subito\n",
      "Disallow: /wiki/Categoria%3ADa_cancellare_subito\n",
      "Disallow: /wiki/Wikipedia:Sospette_violazioni_di_copyright\n",
      "Disallow: /wiki/Wikipedia%3ASospette_violazioni_di_copyright\n",
      "Disallow: /wiki/Categoria:Da_controllare_per_copyright\n",
      "Disallow: /wiki/Categoria%3ADa_controllare_per_copyright\n",
      "Disallow: /wiki/Progetto:Rimozione_contributi_sospetti\n",
      "Disallow: /wiki/Progetto%3ARimozione_contributi_sospetti\n",
      "Disallow: /wiki/Categoria:Da_cancellare_subito_per_violazione_integrale_copyright\n",
      "Disallow: /wiki/Categoria%3ADa_cancellare_subito_per_violazione_integrale_copyright\n",
      "Disallow: /wiki/Progetto:Cococo\n",
      "Disallow: /wiki/Progetto%3ACococo\n",
      "Disallow: /wiki/Discussioni_progetto:Cococo\n",
      "Disallow: /wiki/Discussioni_progetto%3ACococo\n",
      "#\n",
      "# jawiki\n",
      "Disallow: /wiki/%E7%89%B9%E5%88%A5:Search\n",
      "Disallow: /wiki/%E7%89%B9%E5%88%A5%3ASearch\n",
      "# T7239\n",
      "Disallow: /wiki/Wikipedia:%E5%89%8A%E9%99%A4%E4%BE%9D%E9%A0%BC/\n",
      "Disallow: /wiki/Wikipedia%3A%E5%89%8A%E9%99%A4%E4%BE%9D%E9%A0%BC/\n",
      "Disallow: /wiki/Wikipedia:%E5%88%A9%E7%94%A8%E8%80%85%E3%83%9A%E3%83%BC%E3%82%B8%E3%81%AE%E5%89%8A%E9%99%A4%E4%BE%9D%E9%A0%BC\n",
      "Disallow: /wiki/Wikipedia%3A%E5%88%A9%E7%94%A8%E8%80%85%E3%83%9A%E3%83%BC%E3%82%B8%E3%81%AE%E5%89%8A%E9%99%A4%E4%BE%9D%E9%A0%BC\n",
      "# nowiki\n",
      "# T13432\n",
      "Disallow: /wiki/Bruker:\n",
      "Disallow: /wiki/Bruker%3A\n",
      "Disallow: /wiki/Brukerdiskusjon\n",
      "Disallow: /wiki/Wikipedia:Administratorer\n",
      "Disallow: /wiki/Wikipedia%3AAdministratorer\n",
      "Disallow: /wiki/Wikipedia-diskusjon:Administratorer\n",
      "Disallow: /wiki/Wikipedia-diskusjon%3AAdministratorer\n",
      "Disallow: /wiki/Wikipedia:Sletting\n",
      "Disallow: /wiki/Wikipedia%3ASletting\n",
      "Disallow: /wiki/Wikipedia-diskusjon:Sletting\n",
      "Disallow: /wiki/Wikipedia-diskusjon%3ASletting\n",
      "#\n",
      "# plwiki\n",
      "# T10067\n",
      "Disallow: /wiki/Wikipedia:Strony_do_usuni%C4%99cia\n",
      "Disallow: /wiki/Wikipedia%3AStrony_do_usuni%C4%99cia\n",
      "Disallow: /wiki/Wikipedia:Do_usuni%C4%99cia\n",
      "Disallow: /wiki/Wikipedia%3ADo_usuni%C4%99cia\n",
      "Disallow: /wiki/Wikipedia:SDU/\n",
      "Disallow: /wiki/Wikipedia%3ASDU/\n",
      "Disallow: /wiki/Wikipedia:Strony_podejrzane_o_naruszenie_praw_autorskich\n",
      "Disallow: /wiki/Wikipedia%3AStrony_podejrzane_o_naruszenie_praw_autorskich\n",
      "#\n",
      "# ptwiki:\n",
      "# T7394\n",
      "Disallow: /wiki/Wikipedia:Páginas_para_eliminar/\n",
      "Disallow: /wiki/Wikipedia:P%C3%A1ginas_para_eliminar/\n",
      "Disallow: /wiki/Wikipedia%3AP%C3%A1ginas_para_eliminar/\n",
      "Disallow: /wiki/Wikipedia_Discussão:Páginas_para_eliminar/\n",
      "Disallow: /wiki/Wikipedia_Discuss%C3%A3o:P%C3%A1ginas_para_eliminar/\n",
      "Disallow: /wiki/Wikipedia_Discuss%C3%A3o%3AP%C3%A1ginas_para_eliminar/\n",
      "#\n",
      "# rowiki:\n",
      "# T14546\n",
      "Disallow: /wiki/Wikipedia:Pagini_de_%C5%9Fters\n",
      "Disallow: /wiki/Wikipedia%3APagini_de_%C5%9Fters\n",
      "Disallow: /wiki/Discu%C5%A3ie_Wikipedia:Pagini_de_%C5%9Fters\n",
      "Disallow: /wiki/Discu%C5%A3ie_Wikipedia%3APagini_de_%C5%9Fters\n",
      "#\n",
      "# ruwiki:\n",
      "Disallow: /wiki/%D0%A1%D0%BF%D0%B5%D1%86%D0%B8%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5:Search\n",
      "Disallow: /wiki/%D0%A1%D0%BF%D0%B5%D1%86%D0%B8%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%3ASearch\n",
      "#\n",
      "# svwiki:\n",
      "# T12229\n",
      "Disallow: /wiki/Wikipedia%3ASidor_f%C3%B6reslagna_f%C3%B6r_radering\n",
      "Disallow: /wiki/Wikipedia:Sidor_f%C3%B6reslagna_f%C3%B6r_radering\n",
      "Disallow: /wiki/Wikipedia:Sidor_föreslagna_för_radering\n",
      "Disallow: /wiki/Användare\n",
      "Disallow: /wiki/Anv%C3%A4ndare\n",
      "Disallow: /wiki/Användardiskussion\n",
      "Disallow: /wiki/Anv%C3%A4ndardiskussion\n",
      "Disallow: /wiki/Wikipedia:Skyddade_sidnamn\n",
      "Disallow: /wiki/Wikipedia%3ASkyddade_sidnamn\n",
      "# T13291\n",
      "Disallow: /wiki/Wikipedia:Sidor_som_bör_raderas\n",
      "Disallow: /wiki/Wikipedia:Sidor_som_b%C3%B6r_raderas\n",
      "Disallow: /wiki/Wikipedia%3ASidor_som_b%C3%B6r_raderas\n",
      "#\n",
      "# zhwiki:\n",
      "# T7104\n",
      "Disallow: /wiki/Wikipedia:删除投票/侵权\n",
      "Disallow: /wiki/Wikipedia:%E5%88%A0%E9%99%A4%E6%8A%95%E7%A5%A8/%E4%BE%B5%E6%9D%83\n",
      "Disallow: /wiki/Wikipedia:删除投票和请求\n",
      "Disallow: /wiki/Wikipedia:%E5%88%A0%E9%99%A4%E6%8A%95%E7%A5%A8%E5%92%8C%E8%AF%B7%E6%B1%82\n",
      "Disallow: /wiki/Category:快速删除候选\n",
      "Disallow: /wiki/Category:%E5%BF%AB%E9%80%9F%E5%88%A0%E9%99%A4%E5%80%99%E9%80%89\n",
      "Disallow: /wiki/Category:维基百科需要翻译的文章\n",
      "Disallow: /wiki/Category:%E7%BB%B4%E5%9F%BA%E7%99%BE%E7%A7%91%E9%9C%80%E8%A6%81%E7%BF%BB%E8%AF%91%E7%9A%84%E6%96%87%E7%AB%A0\n",
      "#\n",
      "# sister projects\n",
      "#\n",
      "# enwikinews:\n",
      "# T7340\n",
      "Disallow: /wiki/Portal:Prepared_stories/\n",
      "Disallow: /wiki/Portal%3APrepared_stories/\n",
      "#\n",
      "# itwikinews\n",
      "# T11138\n",
      "Disallow: /wiki/Wikinotizie:Richieste_di_cancellazione\n",
      "Disallow: /wiki/Wikinotizie:Sospette_violazioni_di_copyright\n",
      "Disallow: /wiki/Categoria:Da_cancellare_subito\n",
      "Disallow: /wiki/Categoria:Da_cancellare_subito_per_violazione_integrale_copyright\n",
      "Disallow: /wiki/Wikinotizie:Storie_in_preparazione\n",
      "#\n",
      "# enwikiquote:\n",
      "# T17095\n",
      "Disallow: /wiki/Wikiquote:Votes_for_deletion/\n",
      "Disallow: /wiki/Wikiquote%3AVotes_for_deletion/\n",
      "Disallow: /wiki/Wikiquote_talk:Votes_for_deletion/\n",
      "Disallow: /wiki/Wikiquote_talk%3AVotes_for_deletion/\n",
      "Disallow: /wiki/Wikiquote:Votes_for_deletion_archive/\n",
      "Disallow: /wiki/Wikiquote%3AVotes_for_deletion_archive/\n",
      "Disallow: /wiki/Wikiquote_talk:Votes_for_deletion_archive/\n",
      "Disallow: /wiki/Wikiquote_talk%3AVotes_for_deletion_archive/\n",
      "#\n",
      "# enwikibooks\n",
      "Disallow: /wiki/Wikibooks:Votes_for_deletion\n",
      "#\n",
      "# working...\n",
      "Disallow: /wiki/Fundraising_2007/comments\n",
      "#\n",
      "#\n",
      "#\n",
      "#----------------------------------------------------------#\n",
      "#\n",
      "#\n",
      "#\n",
      " # <!-- Please do not remove the space at the start of this line, it breaks the rendering.  http://www.robotstxt.org/orig.html says spaces before comments are OK. --></p><pre>\n",
      "#\n",
      "# Localisable part of robots.txt for en.wikipedia.org\n",
      "#\n",
      "# Edit at https://en.wikipedia.org/w/index.php?title=MediaWiki:Robots.txt&amp;action=edit\n",
      "# Don't add newlines here. All rules set here are active for every user-agent.\n",
      "#\n",
      "# Please check any changes using a syntax validator\n",
      "# Enter https://en.wikipedia.org/robots.txt as the URL to check.\n",
      "#\n",
      "# https://phabricator.wikimedia.org/T16075\n",
      "Disallow: /wiki/MediaWiki:Spam-blacklist\n",
      "Disallow: /wiki/MediaWiki%3ASpam-blacklist\n",
      "Disallow: /wiki/MediaWiki_talk:Spam-blacklist\n",
      "Disallow: /wiki/MediaWiki_talk%3ASpam-blacklist\n",
      "Disallow: /wiki/Wikipedia:WikiProject_Spam\n",
      "Disallow: /wiki/Wikipedia_talk:WikiProject_Spam\n",
      "#\n",
      "# Folks get annoyed when XfD discussions end up the number 1 google hit for\n",
      "# their name. \n",
      "# https://phabricator.wikimedia.org/T16075\n",
      "Disallow: /wiki/Wikipedia:Articles_for_deletion\n",
      "Disallow: /wiki/Wikipedia%3AArticles_for_deletion\n",
      "Disallow: /wiki/Wikipedia:Votes_for_deletion\n",
      "Disallow: /wiki/Wikipedia%3AVotes_for_deletion\n",
      "Disallow: /wiki/Wikipedia:Pages_for_deletion\n",
      "Disallow: /wiki/Wikipedia%3APages_for_deletion\n",
      "Disallow: /wiki/Wikipedia:Miscellany_for_deletion\n",
      "Disallow: /wiki/Wikipedia%3AMiscellany_for_deletion\n",
      "Disallow: /wiki/Wikipedia:Miscellaneous_deletion\n",
      "Disallow: /wiki/Wikipedia%3AMiscellaneous_deletion\n",
      "Disallow: /wiki/Wikipedia:Categories_for_discussion\n",
      "Disallow: /wiki/Wikipedia%3ACategories_for_discussion\n",
      "Disallow: /wiki/Wikipedia:Templates_for_deletion\n",
      "Disallow: /wiki/Wikipedia%3ATemplates_for_deletion\n",
      "Disallow: /wiki/Wikipedia:Redirects_for_discussion\n",
      "Disallow: /wiki/Wikipedia%3ARedirects_for_discussion\n",
      "Disallow: /wiki/Wikipedia:Deletion_review\n",
      "Disallow: /wiki/Wikipedia%3ADeletion_review\n",
      "Disallow: /wiki/Wikipedia:WikiProject_Deletion_sorting\n",
      "Disallow: /wiki/Wikipedia%3AWikiProject_Deletion_sorting\n",
      "Disallow: /wiki/Wikipedia:Files_for_deletion\n",
      "Disallow: /wiki/Wikipedia%3AFiles_for_deletion\n",
      "Disallow: /wiki/Wikipedia:Files_for_discussion\n",
      "Disallow: /wiki/Wikipedia%3AFiles_for_discussion\n",
      "Disallow: /wiki/Wikipedia:Possibly_unfree_files\n",
      "Disallow: /wiki/Wikipedia%3APossibly_unfree_files\n",
      "#\n",
      "# https://phabricator.wikimedia.org/T12288\n",
      "Disallow: /wiki/Wikipedia_talk:Articles_for_deletion\n",
      "Disallow: /wiki/Wikipedia_talk%3AArticles_for_deletion\n",
      "Disallow: /wiki/Wikipedia_talk:Votes_for_deletion\n",
      "Disallow: /wiki/Wikipedia_talk%3AVotes_for_deletion\n",
      "Disallow: /wiki/Wikipedia_talk:Pages_for_deletion\n",
      "Disallow: /wiki/Wikipedia_talk%3APages_for_deletion\n",
      "Disallow: /wiki/Wikipedia_talk:Miscellany_for_deletion\n",
      "Disallow: /wiki/Wikipedia_talk%3AMiscellany_for_deletion\n",
      "Disallow: /wiki/Wikipedia_talk:Miscellaneous_deletion\n",
      "Disallow: /wiki/Wikipedia_talk%3AMiscellaneous_deletion\n",
      "Disallow: /wiki/Wikipedia_talk:Templates_for_deletion\n",
      "Disallow: /wiki/Wikipedia_talk%3ATemplates_for_deletion\n",
      "Disallow: /wiki/Wikipedia_talk:Categories_for_discussion\n",
      "Disallow: /wiki/Wikipedia_talk%3ACategories_for_discussion\n",
      "Disallow: /wiki/Wikipedia_talk:Deletion_review\n",
      "Disallow: /wiki/Wikipedia_talk%3ADeletion_review\n",
      "Disallow: /wiki/Wikipedia_talk:WikiProject_Deletion_sorting\n",
      "Disallow: /wiki/Wikipedia_talk%3AWikiProject_Deletion_sorting\n",
      "Disallow: /wiki/Wikipedia_talk:Files_for_deletion\n",
      "Disallow: /wiki/Wikipedia_talk%3AFiles_for_deletion\n",
      "Disallow: /wiki/Wikipedia_talk:Files_for_discussion\n",
      "Disallow: /wiki/Wikipedia_talk%3AFiles_for_discussion\n",
      "Disallow: /wiki/Wikipedia_talk:Possibly_unfree_files\n",
      "Disallow: /wiki/Wikipedia_talk%3APossibly_unfree_files\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Copyright_problems\n",
      "Disallow: /wiki/Wikipedia%3ACopyright_problems\n",
      "Disallow: /wiki/Wikipedia_talk:Copyright_problems\n",
      "Disallow: /wiki/Wikipedia_talk%3ACopyright_problems\n",
      "Disallow: /wiki/Wikipedia:Suspected_copyright_violations\n",
      "Disallow: /wiki/Wikipedia%3ASuspected_copyright_violations\n",
      "Disallow: /wiki/Wikipedia_talk:Suspected_copyright_violations\n",
      "Disallow: /wiki/Wikipedia_talk%3ASuspected_copyright_violations\n",
      "Disallow: /wiki/Wikipedia:Contributor_copyright_investigations\n",
      "Disallow: /wiki/Wikipedia%3AContributor_copyright_investigations\n",
      "Disallow: /wiki/Wikipedia:Contributor_copyright_investigations\n",
      "Disallow: /wiki/Wikipedia%3AContributor_copyright_investigations\n",
      "Disallow: /wiki/Wikipedia_talk:Contributor_copyright_investigations\n",
      "Disallow: /wiki/Wikipedia_talk%3AContributor_copyright_investigations\n",
      "Disallow: /wiki/Wikipedia_talk:Contributor_copyright_investigations\n",
      "Disallow: /wiki/Wikipedia_talk%3AContributor_copyright_investigations\n",
      "Disallow: /wiki/Wikipedia:Protected_titles\n",
      "Disallow: /wiki/Wikipedia%3AProtected_titles\n",
      "Disallow: /wiki/Wikipedia_talk:Protected_titles\n",
      "Disallow: /wiki/Wikipedia_talk%3AProtected_titles\n",
      "Disallow: /wiki/Wikipedia:Articles_for_creation\n",
      "Disallow: /wiki/Wikipedia%3AArticles_for_creation\n",
      "Disallow: /wiki/Wikipedia_talk:Articles_for_creation\n",
      "Disallow: /wiki/Wikipedia_talk%3AArticles_for_creation\n",
      "Disallow: /wiki/Wikipedia_talk:Article_wizard\n",
      "Disallow: /wiki/Wikipedia_talk%3AArticle_wizard\n",
      "#\n",
      "# https://phabricator.wikimedia.org/T13261\n",
      "Disallow: /wiki/Wikipedia:Requests_for_arbitration\n",
      "Disallow: /wiki/Wikipedia%3ARequests_for_arbitration\n",
      "Disallow: /wiki/Wikipedia_talk:Requests_for_arbitration\n",
      "Disallow: /wiki/Wikipedia_talk%3ARequests_for_arbitration\n",
      "Disallow: /wiki/Wikipedia:Requests_for_comment\n",
      "Disallow: /wiki/Wikipedia%3ARequests_for_comment\n",
      "Disallow: /wiki/Wikipedia_talk:Requests_for_comment\n",
      "Disallow: /wiki/Wikipedia_talk%3ARequests_for_comment\n",
      "Disallow: /wiki/Wikipedia:Requests_for_adminship\n",
      "Disallow: /wiki/Wikipedia%3ARequests_for_adminship\n",
      "Disallow: /wiki/Wikipedia_talk:Requests_for_adminship\n",
      "Disallow: /wiki/Wikipedia_talk%3ARequests_for_adminship\n",
      "#\n",
      "# https://phabricator.wikimedia.org/T14111\n",
      "Disallow: /wiki/Wikipedia:Requests_for_checkuser\n",
      "Disallow: /wiki/Wikipedia%3ARequests_for_checkuser\n",
      "Disallow: /wiki/Wikipedia_talk:Requests_for_checkuser\n",
      "Disallow: /wiki/Wikipedia_talk%3ARequests_for_checkuser\n",
      "#\n",
      "# https://phabricator.wikimedia.org/T15398\n",
      "Disallow: /wiki/Wikipedia:WikiProject_Spam\n",
      "Disallow: /wiki/Wikipedia%3AWikiProject_Spam\n",
      "#\n",
      "# https://phabricator.wikimedia.org/T16793\n",
      "Disallow: /wiki/Wikipedia:Changing_username\n",
      "Disallow: /wiki/Wikipedia%3AChanging_username\n",
      "Disallow: /wiki/Wikipedia:Changing_username\n",
      "Disallow: /wiki/Wikipedia%3AChanging_username\n",
      "Disallow: /wiki/Wikipedia_talk:Changing_username\n",
      "Disallow: /wiki/Wikipedia_talk%3AChanging_username\n",
      "Disallow: /wiki/Wikipedia_talk:Changing_username\n",
      "Disallow: /wiki/Wikipedia_talk%3AChanging_username\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Administrators%27_noticeboard\n",
      "Disallow: /wiki/Wikipedia%3AAdministrators%27_noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk:Administrators%27_noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk%3AAdministrators%27_noticeboard\n",
      "Disallow: /wiki/Wikipedia:Community_sanction_noticeboard\n",
      "Disallow: /wiki/Wikipedia%3ACommunity_sanction_noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk:Community_sanction_noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk%3ACommunity_sanction_noticeboard\n",
      "Disallow: /wiki/Wikipedia:Bureaucrats%27_noticeboard\n",
      "Disallow: /wiki/Wikipedia%3ABureaucrats%27_noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk:Bureaucrats%27_noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk%3ABureaucrats%27_noticeboard\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Sockpuppet_investigations\n",
      "Disallow: /wiki/Wikipedia%3ASockpuppet_investigations\n",
      "Disallow: /wiki/Wikipedia_talk:Sockpuppet_investigations\n",
      "Disallow: /wiki/Wikipedia_talk%3ASockpuppet_investigations\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Neutral_point_of_view/Noticeboard\n",
      "Disallow: /wiki/Wikipedia%3ANeutral_point_of_view/Noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk:Neutral_point_of_view/Noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk%3ANeutral_point_of_view/Noticeboard\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:No_original_research/noticeboard\n",
      "Disallow: /wiki/Wikipedia%3ANo_original_research/noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk:No_original_research/noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk%3ANo_original_research/noticeboard\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Fringe_theories/Noticeboard\n",
      "Disallow: /wiki/Wikipedia%3AFringe_theories/Noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk:Fringe_theories/Noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk%3AFringe_theories/Noticeboard\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Conflict_of_interest/Noticeboard\n",
      "Disallow: /wiki/Wikipedia%3AConflict_of_interest/Noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk:Conflict_of_interest/Noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk%3AConflict_of_interest/Noticeboard\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Long-term_abuse\n",
      "Disallow: /wiki/Wikipedia%3ALong-term_abuse\n",
      "Disallow: /wiki/Wikipedia_talk:Long-term_abuse\n",
      "Disallow: /wiki/Wikipedia_talk%3ALong-term_abuse\n",
      "Disallow: /wiki/Wikipedia:Long_term_abuse\n",
      "Disallow: /wiki/Wikipedia%3ALong_term_abuse\n",
      "Disallow: /wiki/Wikipedia_talk:Long_term_abuse\n",
      "Disallow: /wiki/Wikipedia_talk%3ALong_term_abuse\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Wikiquette_assistance\n",
      "Disallow: /wiki/Wikipedia%3AWikiquette_assistance\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Abuse_reports\n",
      "Disallow: /wiki/Wikipedia%3AAbuse_reports\n",
      "Disallow: /wiki/Wikipedia_talk:Abuse_reports\n",
      "Disallow: /wiki/Wikipedia_talk%3AAbuse_reports\n",
      "Disallow: /wiki/Wikipedia:Abuse_response\n",
      "Disallow: /wiki/Wikipedia%3AAbuse_response\n",
      "Disallow: /wiki/Wikipedia_talk:Abuse_response\n",
      "Disallow: /wiki/Wikipedia_talk%3AAbuse_response\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Reliable_sources/Noticeboard\n",
      "Disallow: /wiki/Wikipedia%3AReliable_sources/Noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk:Reliable_sources/Noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk%3AReliable_sources/Noticeboard\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Suspected_sock_puppets\n",
      "Disallow: /wiki/Wikipedia%3ASuspected_sock_puppets\n",
      "Disallow: /wiki/Wikipedia_talk:Suspected_sock_puppets\n",
      "Disallow: /wiki/Wikipedia_talk%3ASuspected_sock_puppets\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Biographies_of_living_persons/Noticeboard\n",
      "Disallow: /wiki/Wikipedia%3ABiographies_of_living_persons/Noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk:Biographies_of_living_persons/Noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk%3ABiographies_of_living_persons/Noticeboard\n",
      "Disallow: /wiki/Wikipedia:Biographies_of_living_persons%2FNoticeboard\n",
      "Disallow: /wiki/Wikipedia%3ABiographies_of_living_persons%2FNoticeboard\n",
      "Disallow: /wiki/Wikipedia_talk:Biographies_of_living_persons%2FNoticeboard\n",
      "Disallow: /wiki/Wikipedia_talk%3ABiographies_of_living_persons%2FNoticeboard\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Content_noticeboard\n",
      "Disallow: /wiki/Wikipedia%3AContent_noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk:Content_noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk%3AContent_noticeboard\n",
      "#\n",
      "Disallow: /wiki/Template:Editnotices\n",
      "Disallow: /wiki/Template%3AEditnotices\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Arbitration\n",
      "Disallow: /wiki/Wikipedia%3AArbitration\n",
      "Disallow: /wiki/Wikipedia_talk:Arbitration\n",
      "Disallow: /wiki/Wikipedia_talk%3AArbitration\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Arbitration_Committee\n",
      "Disallow: /wiki/Wikipedia%3AArbitration_Committee\n",
      "Disallow: /wiki/Wikipedia_talk:Arbitration_Committee\n",
      "Disallow: /wiki/Wikipedia_talk%3AArbitration_Committee\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Arbitration_Committee_Elections\n",
      "Disallow: /wiki/Wikipedia%3AArbitration_Committee_Elections\n",
      "Disallow: /wiki/Wikipedia_talk:Arbitration_Committee_Elections\n",
      "Disallow: /wiki/Wikipedia_talk%3AArbitration_Committee_Elections\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Mediation_Committee\n",
      "Disallow: /wiki/Wikipedia%3AMediation_Committee\n",
      "Disallow: /wiki/Wikipedia_talk:Mediation_Committee\n",
      "Disallow: /wiki/Wikipedia_talk%3AMediation_Committee\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Mediation_Cabal/Cases\n",
      "Disallow: /wiki/Wikipedia%3AMediation_Cabal/Cases\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Requests_for_bureaucratship\n",
      "Disallow: /wiki/Wikipedia%3ARequests_for_bureaucratship\n",
      "Disallow: /wiki/Wikipedia_talk:Requests_for_bureaucratship\n",
      "Disallow: /wiki/Wikipedia_talk%3ARequests_for_bureaucratship\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Administrator_review\n",
      "Disallow: /wiki/Wikipedia%3AAdministrator_review\n",
      "Disallow: /wiki/Wikipedia_talk:Administrator_review\n",
      "Disallow: /wiki/Wikipedia_talk%3AAdministrator_review\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Editor_review\n",
      "Disallow: /wiki/Wikipedia%3AEditor_review\n",
      "Disallow: /wiki/Wikipedia_talk:Editor_review\n",
      "Disallow: /wiki/Wikipedia_talk%3AEditor_review\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Article_Incubator\n",
      "Disallow: /wiki/Wikipedia%3AArticle_Incubator\n",
      "Disallow: /wiki/Wikipedia_talk:Article_Incubator\n",
      "Disallow: /wiki/Wikipedia_talk%3AArticle_Incubator\n",
      "#\n",
      "Disallow: /wiki/Category:Noindexed_pages\n",
      "Disallow: /wiki/Category%3ANoindexed_pages\n",
      "#\n",
      "# User sandboxes for modules and Template Styles are placed in these subpages for testing\n",
      "#\n",
      "Disallow: /wiki/Module:Sandbox\n",
      "Disallow: /wiki/Module%3ASandbox\n",
      "Disallow: /wiki/Template:TemplateStyles_sandbox\n",
      "Disallow: /wiki/Template%3ATemplateStyles_sandbox\n",
      "#\n",
      "# </pre></body></html>\n"
     ]
    }
   ],
   "source": [
    "check(url=\"https://en.wikipedia.org/wiki/Main_Page\",\n",
    "     url2=\"https://en.wikipedia.org/robots.txt\")             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5de25e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki(url):                                             # Defining function to get headings from wikipedia's main page\n",
    "    page= requests.get(url)                                     # for getting respnse and hitting wikipedia server\n",
    "    parse= BeautifulSoup(page.content)                       # to get contents of the webpage\n",
    "    title=[]                                                 # Creating an empty list to store data\n",
    "    for i in parse.find_all('span', class_=\"mw-headline\"):  # condition to get headings\n",
    "        title.append(i.text)                                # storing headers in the empty list we had created\n",
    "    heading= pd.DataFrame(title, columns=[\"Title\"])         # Creating a Data Frame or table\n",
    "    print(heading)                                          # Displaying results in a table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46b8404c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Title\n",
      "0           Welcome to Wikipedia\n",
      "1  From today's featured article\n",
      "2               Did you know ...\n",
      "3                    In the news\n",
      "4                    On this day\n",
      "5       Today's featured picture\n",
      "6       Other areas of Wikipedia\n",
      "7    Wikipedia's sister projects\n",
      "8            Wikipedia languages\n"
     ]
    }
   ],
   "source": [
    "wiki(url=\"https://en.wikipedia.org/wiki/Main_Page\")  # Recalling the function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ce4305",
   "metadata": {},
   "source": [
    "Question 2:\n",
    "\n",
    "Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release)\n",
    "and make data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb5ca34",
   "metadata": {},
   "source": [
    "A: To start with web scraping we must first check with the legality and server permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ae3ff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(url,url2):                          # Defining function to check whether connection can be established and permissions\n",
    "    page= requests.get(url)              # Checking for the server to be accessible of the website to be scrapped\n",
    "    print(page,\"\\n\")                     # Display result\n",
    "    \n",
    "    if page.status_code==200:                        # Condition for accessibility\n",
    "        print (\"Server is accessible for Web Scrapping\",\"\\n\",\"\\n\")\n",
    "    else:\n",
    "        print(\"Server is not accessible for Web Scrapping\",\"\\n\",\"\\n\")\n",
    "        \n",
    "    page2=requests.get(url2)                  # To connect with the desired webpage\n",
    "    permission=BeautifulSoup(page2.content)   # To parse the permissions\n",
    "    print (permission)                        # Display permissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ce2cda",
   "metadata": {},
   "source": [
    "Recalling the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1effbad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]> \n",
      "\n",
      "Server is accessible for Web Scrapping \n",
      " \n",
      "\n",
      "<html><body><p># robots.txt for https://www.imdb.com properties\n",
      "User-agent: *\n",
      "Disallow: /OnThisDay\n",
      "Disallow: /ads/\n",
      "Disallow: /ap/\n",
      "Disallow: /mymovies/\n",
      "Disallow: /r/\n",
      "Disallow: /register\n",
      "Disallow: /registration/\n",
      "Disallow: /search/name-text\n",
      "Disallow: /search/title-text\n",
      "Disallow: /find\n",
      "Disallow: /find$\n",
      "Disallow: /find/\n",
      "Disallow: /tvschedule\n",
      "Disallow: /updates\n",
      "Disallow: /watch/_ajax/option\n",
      "Disallow: /_json/video/mon\n",
      "Disallow: /_json/getAdsForMediaViewer/\n",
      "Disallow: /list/ls*/_ajax\n",
      "Disallow: /*/*/rg*/mediaviewer/rm*/tr\n",
      "Disallow: /*/rg*/mediaviewer/rm*/tr\n",
      "Disallow: /*/mediaviewer/*/tr\n",
      "Disallow: /title/tt*/mediaviewer/rm*/tr\n",
      "Disallow: /name/nm*/mediaviewer/rm*/tr\n",
      "Disallow: /gallery/rg*/mediaviewer/rm*/tr\n",
      "Disallow: /tr/\n",
      "Disallow: /title/tt*/watchoptions\n",
      "Disallow: /search/title/?title_type=feature,tv_movie,tv_miniseries,documentary,short,video,tv_short&amp;release_date=,2020-12-31&amp;lists=%21ls538187658,%21ls539867036,%21ls538186228&amp;view=simple&amp;sort=num_votes,asc&amp;aft\n",
      "\n",
      "User-agent: Baiduspider\n",
      "Disallow: /list/*\n",
      "Disallow: /user/*</p></body></html>\n"
     ]
    }
   ],
   "source": [
    "check(url=\"https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc\",\n",
    "     url2=\"https://www.imdb.com/robots.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f29a87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Function\n",
    "def imdb(url1,url2):\n",
    "\n",
    "# Creating empty list\n",
    "    col1=[]\n",
    "    col2=[]\n",
    "    col3=[]\n",
    "    col4=[]\n",
    "    col5=[]\n",
    "    col6=[]\n",
    "    col7=[]\n",
    "    col8=[]\n",
    "    \n",
    "# Setting rows and columns for max result display\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_rows', None)\n",
    "\n",
    "# To establish connection with the required webpage\n",
    "    page1= requests.get(url1)\n",
    "    page2= requests.get(url2)\n",
    "\n",
    "# Fetching contents of the webpage\n",
    "    parse1=BeautifulSoup(page1.content)\n",
    "    parse2= BeautifulSoup(page2.content)\n",
    "    \n",
    "# Condition to fetch the desired content and saving the result in the specified list    \n",
    "    for i in parse1.find_all('span', class_=\"lister-item-index unbold text-primary\"):\n",
    "        col1.append(i.text)\n",
    "        \n",
    "    for i in parse1.find_all('h3', class_=\"lister-item-header\"):\n",
    "        col2.append(i.text)\n",
    "        \n",
    "    for i in parse1.find_all('div', class_=\"inline-block ratings-imdb-rating\"):\n",
    "        col3.append(i.text)\n",
    "        \n",
    "    for i in parse1.find_all('span', class_=\"lister-item-year text-muted unbold\"):\n",
    "        col4.append(i.text)\n",
    "        \n",
    "    for i in parse2.find_all('span', class_=\"lister-item-index unbold text-primary\"):\n",
    "        col5.append(i.text)\n",
    "        \n",
    "    for i in parse2.find_all('h3', class_=\"lister-item-header\"):\n",
    "        col6.append(i.text)\n",
    "        \n",
    "    for i in parse2.find_all('div', class_=\"inline-block ratings-imdb-rating\"):\n",
    "        col7.append(i.text)\n",
    "        \n",
    "    for i in parse2.find_all('span', class_=\"lister-item-year text-muted unbold\"):\n",
    "        col8.append(i.text)\n",
    " # Creating Data Frames\n",
    "    table1= pd.DataFrame({\"Rank\":col1, \"Name\":col2,\"Rating\":col3,\"Year Of Release\":col4 })      \n",
    "    table2= pd.DataFrame({\"Rank\":col5, \"Name\":col6,\"Rating\":col7,\"Year Of Release\":col8 })  \n",
    "    table= pd.DataFrame()\n",
    "    \n",
    "# Merging the results in two tables to a single table\n",
    "    table= pd.concat([table1,table2],axis=0,)\n",
    "# To remove \"\\n\" tags\n",
    "    table=table.replace('\\n','',regex=True)\n",
    "    \n",
    "# To drop index from being displayed\n",
    "    table=table.to_string(index=False, col_space=15,)\n",
    "    \n",
    "# To display result\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fa5bad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Rank                                                                          Name          Rating Year Of Release\n",
      "             1.                                              1.The Shawshank Redemption(1994)             9.3          (1994)\n",
      "             2.                                                         2.The Godfather(1972)             9.2          (1972)\n",
      "             3.                                                       3.The Dark Knight(2008)             9.0          (2008)\n",
      "             4.                         4.The Lord of the Rings: The Return of the King(2003)             9.0          (2003)\n",
      "             5.                                                      5.Schindler's List(1993)             9.0          (1993)\n",
      "             6.                                                 6.The Godfather Part II(1974)             9.0          (1974)\n",
      "             7.                                                          7.12 Angry Men(1957)             9.0          (1957)\n",
      "             8.                                                          8.Pulp Fiction(1994)             8.9          (1994)\n",
      "             9.                                                             9.Inception(2010)             8.8          (2010)\n",
      "            10.                                10.The Lord of the Rings: The Two Towers(2002)             8.8          (2002)\n",
      "            11.                                                           11.Fight Club(1999)             8.8          (1999)\n",
      "            12.                    12.The Lord of the Rings: The Fellowship of the Ring(2001)             8.8          (2001)\n",
      "            13.                                                         13.Forrest Gump(1994)             8.8          (1994)\n",
      "            14.                                      14.Il buono, il brutto, il cattivo(1966)             8.8          (1966)\n",
      "            15.                                                           15.The Matrix(1999)             8.7          (1999)\n",
      "            16.                                                           16.Goodfellas(1990)             8.7          (1990)\n",
      "            17.                                              17.The Empire Strikes Back(1980)             8.7          (1980)\n",
      "            18.                                      18.One Flew Over the Cuckoo's Nest(1975)             8.7          (1975)\n",
      "            19.                                                    19.Top Gun: Maverick(2022)             8.6          (2022)\n",
      "            20.                                                         20.Interstellar(2014)             8.6          (2014)\n",
      "            21.                                                       21.Cidade de Deus(2002)             8.6          (2002)\n",
      "            22.                                        22.Sen to Chihiro no kamikakushi(2001)             8.6          (2001)\n",
      "            23.                                                  23.Saving Private Ryan(1998)             8.6          (1998)\n",
      "            24.                                                       24.The Green Mile(1999)             8.6          (1999)\n",
      "            25.                                                      25.La vita è bella(1997)             8.6          (1997)\n",
      "            26.                                                                26.Se7en(1995)             8.6          (1995)\n",
      "            27.                                           27.Terminator 2: Judgment Day(1991)             8.6          (1991)\n",
      "            28.                                             28.The Silence of the Lambs(1991)             8.6          (1991)\n",
      "            29.                                                            29.Star Wars(1977)             8.6          (1977)\n",
      "            30.                                                              30.Seppuku(1962)             8.6          (1962)\n",
      "            31.                                                 31.Shichinin no samurai(1954)             8.6          (1954)\n",
      "            32.                                                32.It's a Wonderful Life(1946)             8.6          (1946)\n",
      "            33.                                                         33.Gisaengchung(2019)             8.5          (2019)\n",
      "            34.                                                             34.Whiplash(2014)             8.5          (2014)\n",
      "            35.                                                     35.The Intouchables(2011)             8.5          (2011)\n",
      "            36.                                                         36.The Prestige(2006)             8.5          (2006)\n",
      "            37.                                                         37.The Departed(2006)             8.5          (2006)\n",
      "            38.                                                          38.The Pianist(2002)             8.5          (2002)\n",
      "            39.                                                            39.Gladiator(2000)             8.5          (2000)\n",
      "            40.                                                   40.American History X(1998)             8.5          (1998)\n",
      "            41.                                                   41.The Usual Suspects(1995)             8.5          (1995)\n",
      "            42.                                                                 42.Léon(1994)             8.5          (1994)\n",
      "            43.                                                        43.The Lion King(1994)             8.5          (1994)\n",
      "            44.                                                44.Nuovo Cinema Paradiso(1988)             8.5          (1988)\n",
      "            45.                                                       45.Hotaru no haka(1988)             8.5          (1988)\n",
      "            46.                                                   46.Back to the Future(1985)             8.5          (1985)\n",
      "            47.                                                       47.Apocalypse Now(1979)             8.5          (1979)\n",
      "            48.                                                                48.Alien(1979)             8.5          (1979)\n",
      "            49.                                         49.Once Upon a Time in the West(1968)             8.5          (1968)\n",
      "            50.                                                               50.Psycho(1960)             8.5          (1960)\n",
      "            51.                                                          51.Rear Window(1954)             8.5          (1954)\n",
      "            52.                                                           52.Casablanca(1942)             8.5          (1942)\n",
      "            53.                                                         53.Modern Times(1936)             8.5          (1936)\n",
      "            54.                                                          54.City Lights(1931)             8.5          (1931)\n",
      "            55.                                                           55.Capharnaüm(2018)             8.4          (2018)\n",
      "            56.                                                            56.Joker(I) (2019)             8.4      (I) (2019)\n",
      "            57.                                                       57.Kimi no na wa.(2016)             8.4          (2016)\n",
      "            58.                                    58.Spider-Man: Into the Spider-Verse(2018)             8.4          (2018)\n",
      "            59.                                                    59.Avengers: Endgame(2019)             8.4          (2019)\n",
      "            60.                                               60.Avengers: Infinity War(2018)             8.4          (2018)\n",
      "            61.                                                             61.Coco(I) (2017)             8.4      (I) (2017)\n",
      "            62.                                                     62.Django Unchained(2012)             8.4          (2012)\n",
      "            63.                                                63.The Dark Knight Rises(2012)             8.4          (2012)\n",
      "            64.                                                             64.3 Idiots(2009)             8.4          (2009)\n",
      "            65.                                                               65.WALL·E(2008)             8.4          (2008)\n",
      "            66.                                                  66.The Lives of Others(2006)             8.4          (2006)\n",
      "            67.                                                             67.Oldeuboi(2003)             8.4          (2003)\n",
      "            68.                                                              68.Memento(2000)             8.4          (2000)\n",
      "            69.                                                      69.American Beauty(1999)             8.4          (1999)\n",
      "            70.                                                        70.Mononoke-hime(1997)             8.4          (1997)\n",
      "            71.                                                           71.Braveheart(1995)             8.4          (1995)\n",
      "            72.                                                               72.Aliens(1986)             8.4          (1986)\n",
      "            73.                                                              73.Amadeus(1984)             8.4          (1984)\n",
      "            74.                                              74.Raiders of the Lost Ark(1981)             8.4          (1981)\n",
      "            75.                                                             75.Das Boot(1981)             8.4          (1981)\n",
      "            76.                                                          76.The Shining(1980)             8.4          (1980)\n",
      "            77.                                                    77.Tengoku to jigoku(1963)             8.4          (1963)\n",
      "            78. 78.Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb(1964)             8.4          (1964)\n",
      "            79.                                          79.Witness for the Prosecution(1957)             8.4          (1957)\n",
      "            80.                                                       80.Paths of Glory(1957)             8.4          (1957)\n",
      "            81.                                                         81.Sunset Blvd.(1950)             8.4          (1950)\n",
      "            82.                                                   82.The Great Dictator(1940)             8.4          (1940)\n",
      "            83.                                                               83.Jagten(2012)             8.3          (2012)\n",
      "            84.                                                          84.Toy Story 3(2010)             8.3          (2010)\n",
      "            85.                                                 85.Inglourious Basterds(2009)             8.3          (2009)\n",
      "            86.                                86.Eternal Sunshine of the Spotless Mind(2004)             8.3          (2004)\n",
      "            87.                                  87.Le fabuleux destin d'Amélie Poulain(2001)             8.3          (2001)\n",
      "            88.                                                  88.Requiem for a Dream(2000)             8.3          (2000)\n",
      "            89.                                                    89.Good Will Hunting(1997)             8.3          (1997)\n",
      "            90.                                                            90.Toy Story(1995)             8.3          (1995)\n",
      "            91.                                                       91.Reservoir Dogs(1992)             8.3          (1992)\n",
      "            92.                                          92.Once Upon a Time in America(1984)             8.3          (1984)\n",
      "            93.                           93.Star Wars: Episode VI - Return of the Jedi(1983)             8.3          (1983)\n",
      "            94.                                                94.2001: A Space Odyssey(1968)             8.3          (1968)\n",
      "            95.                                                   95.Lawrence of Arabia(1962)             8.3          (1962)\n",
      "            96.                                                   96.North by Northwest(1959)             8.3          (1959)\n",
      "            97.                                                              97.Vertigo(1958)             8.3          (1958)\n",
      "            98.                                                  98.Singin' in the Rain(1952)             8.3          (1952)\n",
      "            99.                                                         99.Citizen Kane(1941)             8.3          (1941)\n",
      "           100.                                   100.M - Eine Stadt sucht einen Mörder(1931)             8.3          (1931)\n"
     ]
    }
   ],
   "source": [
    "# Recalling the function\n",
    "imdb(url1=\"https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc\",\n",
    "    url2=\"https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc&start=51&ref_=adv_nxt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04be71f",
   "metadata": {},
   "source": [
    "Question 3:\n",
    "    \n",
    "Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of\n",
    "release) and make data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cab42eb",
   "metadata": {},
   "source": [
    "A: To start with web scraping we must first check with the legality and server permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0d6a70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(url,url2):                          # Defining function to check whether connection can be established and permissions\n",
    "    page= requests.get(url)              # Checking for the server to be accessible of the website to be scrapped\n",
    "    print(page,\"\\n\")                     # Display result\n",
    "    \n",
    "    if page.status_code==200:                        # Condition for accessibility\n",
    "        print (\"Server is accessible for Web Scrapping\",\"\\n\",\"\\n\")\n",
    "    else:\n",
    "        print(\"Server is not accessible for Web Scrapping\",\"\\n\",\"\\n\")\n",
    "        \n",
    "    page2=requests.get(url2)                  # To connect with the desired webpage\n",
    "    permission=BeautifulSoup(page2.content)   # To parse the permissions\n",
    "    print (permission)                        # Display permissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86e5a31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]> \n",
      "\n",
      "Server is accessible for Web Scrapping \n",
      " \n",
      "\n",
      "<html><body><p># robots.txt for https://www.imdb.com properties\n",
      "User-agent: *\n",
      "Disallow: /OnThisDay\n",
      "Disallow: /ads/\n",
      "Disallow: /ap/\n",
      "Disallow: /mymovies/\n",
      "Disallow: /r/\n",
      "Disallow: /register\n",
      "Disallow: /registration/\n",
      "Disallow: /search/name-text\n",
      "Disallow: /search/title-text\n",
      "Disallow: /find\n",
      "Disallow: /find$\n",
      "Disallow: /find/\n",
      "Disallow: /tvschedule\n",
      "Disallow: /updates\n",
      "Disallow: /watch/_ajax/option\n",
      "Disallow: /_json/video/mon\n",
      "Disallow: /_json/getAdsForMediaViewer/\n",
      "Disallow: /list/ls*/_ajax\n",
      "Disallow: /*/*/rg*/mediaviewer/rm*/tr\n",
      "Disallow: /*/rg*/mediaviewer/rm*/tr\n",
      "Disallow: /*/mediaviewer/*/tr\n",
      "Disallow: /title/tt*/mediaviewer/rm*/tr\n",
      "Disallow: /name/nm*/mediaviewer/rm*/tr\n",
      "Disallow: /gallery/rg*/mediaviewer/rm*/tr\n",
      "Disallow: /tr/\n",
      "Disallow: /title/tt*/watchoptions\n",
      "Disallow: /search/title/?title_type=feature,tv_movie,tv_miniseries,documentary,short,video,tv_short&amp;release_date=,2020-12-31&amp;lists=%21ls538187658,%21ls539867036,%21ls538186228&amp;view=simple&amp;sort=num_votes,asc&amp;aft\n",
      "\n",
      "User-agent: Baiduspider\n",
      "Disallow: /list/*\n",
      "Disallow: /user/*</p></body></html>\n"
     ]
    }
   ],
   "source": [
    "# Recalling the function\n",
    "check(url=\"https://www.imdb.com/india/top-rated-indian-movies/?sort=rk,asc&mode=simple&page=1/\",\n",
    "     url2=\"https://www.imdb.com/robots.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e5d708a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_indian(url):\n",
    "# Creating empty list\n",
    "    rank=[]\n",
    "    name=[]\n",
    "    rating=[]\n",
    "    year=[]\n",
    "        \n",
    "# Setting rows and columns for max result display\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_rows', None)\n",
    "\n",
    "# To establish connection with the required webpage\n",
    "#url=\"https://www.imdb.com/india/top-rated-indian-movies/?sort=rk,asc&mode=simple&page=1\" \n",
    "    page= requests.get(url)\n",
    "    \n",
    "\n",
    "# Fetching contents of the webpage\n",
    "    parse=BeautifulSoup(page.content)\n",
    "\n",
    "# Condition to fetch the desired content and saving the result in the specified list    \n",
    "\n",
    "    for i in parse.find_all('td', class_=\"titleColumn\"):\n",
    "        rank.append(i.contents)\n",
    "        \n",
    "    for i in parse.find_all('a'):\n",
    "        name.append(i.text)\n",
    "        \n",
    "    for i in parse.find_all('td',class_=\"ratingColumn imdbRating\"):\n",
    "        rating.append(i.contents)\n",
    "        \n",
    "    for i in parse.find_all('span', class_=\"secondaryInfo\"):\n",
    "        year.append(i.contents)\n",
    "        \n",
    "    new_col2=name[58:557:2]\n",
    "    new_col4=year[0:250]\n",
    "    \n",
    "    table=pd.DataFrame(rank)\n",
    "    table1=table.loc[:,0:0:]\n",
    "    table1=table1.replace('\\n',\"\",regex=True)   \n",
    "    \n",
    "\n",
    "# To drop index from being displayed\n",
    "    \n",
    "    new_col1=table1.values.tolist()\n",
    "    table2= pd.DataFrame({\"Rank\":new_col1, \"Name\":new_col2,\"Rating\":rating,\"Year Of Release\":new_col4 }) \n",
    "    table2=table2.replace('\\n', regex=True)\n",
    "    print(table2.head(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec89bd80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Rank                               Name           Rating  \\\n",
      "0     [      1.      ]                           Jai Bhim  [\\n, [8.4], \\n]   \n",
      "1     [      2.      ]                         Anbe Sivam  [\\n, [8.4], \\n]   \n",
      "2     [      3.      ]                            Golmaal  [\\n, [8.4], \\n]   \n",
      "3     [      4.      ]                            Nayakan  [\\n, [8.4], \\n]   \n",
      "4     [      5.      ]                  Pariyerum Perumal  [\\n, [8.4], \\n]   \n",
      "5     [      6.      ]                           3 Idiots  [\\n, [8.3], \\n]   \n",
      "6     [      7.      ]                        Apur Sansar  [\\n, [8.3], \\n]   \n",
      "7     [      8.      ]                   Manichitrathazhu  [\\n, [8.3], \\n]   \n",
      "8     [      9.      ]                       Black Friday  [\\n, [8.3], \\n]   \n",
      "9    [      10.      ]                  Kumbalangi Nights  [\\n, [8.3], \\n]   \n",
      "10   [      11.      ]                  C/o Kancharapalem  [\\n, [8.3], \\n]   \n",
      "11   [      12.      ]                   Taare Zameen Par  [\\n, [8.3], \\n]   \n",
      "12   [      13.      ]                              #Home  [\\n, [8.3], \\n]   \n",
      "13   [      14.      ]                             Vikram  [\\n, [8.3], \\n]   \n",
      "14   [      15.      ]                    Soorarai Pottru  [\\n, [8.3], \\n]   \n",
      "15   [      16.      ]                             Dangal  [\\n, [8.3], \\n]   \n",
      "16   [      17.      ]                           Kireedam  [\\n, [8.3], \\n]   \n",
      "17   [      18.      ]                             Kaithi  [\\n, [8.3], \\n]   \n",
      "18   [      19.      ]                             Jersey  [\\n, [8.3], \\n]   \n",
      "19   [      20.      ]                       Thevar Magan  [\\n, [8.2], \\n]   \n",
      "20   [      21.      ]                    Pather Panchali  [\\n, [8.2], \\n]   \n",
      "21   [      22.      ]                             Asuran  [\\n, [8.2], \\n]   \n",
      "22   [      23.      ]                                 96  [\\n, [8.2], \\n]   \n",
      "23   [      24.      ]                         Visaaranai  [\\n, [8.2], \\n]   \n",
      "24   [      25.      ]                         Thalapathi  [\\n, [8.2], \\n]   \n",
      "25   [      26.      ]                          Natsamrat  [\\n, [8.2], \\n]   \n",
      "26   [      27.      ]                Sarpatta Parambarai  [\\n, [8.2], \\n]   \n",
      "27   [      28.      ]                         Drishyam 2  [\\n, [8.2], \\n]   \n",
      "28   [      29.      ]                       Sardar Udham  [\\n, [8.2], \\n]   \n",
      "29   [      30.      ]                       Thani Oruvan  [\\n, [8.2], \\n]   \n",
      "30   [      31.      ]                          Aparajito  [\\n, [8.2], \\n]   \n",
      "31   [      32.      ]                       Vada Chennai  [\\n, [8.2], \\n]   \n",
      "32   [      33.      ]                 Jaane Bhi Do Yaaro  [\\n, [8.2], \\n]   \n",
      "33   [      34.      ]                  Khosla Ka Ghosla!  [\\n, [8.2], \\n]   \n",
      "34   [      35.      ]                           Drishyam  [\\n, [8.1], \\n]   \n",
      "35   [      36.      ]                      Chupke Chupke  [\\n, [8.1], \\n]   \n",
      "36   [      37.      ]                            Peranbu  [\\n, [8.1], \\n]   \n",
      "37   [      38.      ]        Agent Sai Srinivasa Athreya  [\\n, [8.1], \\n]   \n",
      "38   [      39.      ]                            Anniyan  [\\n, [8.1], \\n]   \n",
      "39   [      40.      ]                           Mahanati  [\\n, [8.1], \\n]   \n",
      "40   [      41.      ]                       Super Deluxe  [\\n, [8.1], \\n]   \n",
      "41   [      42.      ]                     Bangalore Days  [\\n, [8.1], \\n]   \n",
      "42   [      43.      ]                              Satya  [\\n, [8.1], \\n]   \n",
      "43   [      44.      ]                             Premam  [\\n, [8.1], \\n]   \n",
      "44   [      45.      ]                           Ratsasan  [\\n, [8.1], \\n]   \n",
      "45   [      46.      ]                          Devasuram  [\\n, [8.1], \\n]   \n",
      "46   [      47.      ]                 Bhaag Milkha Bhaag  [\\n, [8.1], \\n]   \n",
      "47   [      48.      ]                 Gangs of Wasseypur  [\\n, [8.1], \\n]   \n",
      "48   [      49.      ]                              Aruvi  [\\n, [8.1], \\n]   \n",
      "49   [      50.      ]                          Andhadhun  [\\n, [8.1], \\n]   \n",
      "50   [      51.      ]                           Drishyam  [\\n, [8.1], \\n]   \n",
      "51   [      52.      ]              Kannathil Muthamittal  [\\n, [8.1], \\n]   \n",
      "52   [      53.      ]                              Guide  [\\n, [8.1], \\n]   \n",
      "53   [      54.      ]                             Shahid  [\\n, [8.1], \\n]   \n",
      "54   [      55.      ]                           Chithram  [\\n, [8.1], \\n]   \n",
      "55   [      56.      ]                             Iruvar  [\\n, [8.1], \\n]   \n",
      "56   [      57.      ]                             Sairat  [\\n, [8.1], \\n]   \n",
      "57   [      58.      ]           Zindagi Na Milegi Dobara  [\\n, [8.1], \\n]   \n",
      "58   [      59.      ]                   Paan Singh Tomar  [\\n, [8.1], \\n]   \n",
      "59   [      60.      ]                       Vikram Vedha  [\\n, [8.1], \\n]   \n",
      "60   [      61.      ]                            Tumbbad  [\\n, [8.1], \\n]   \n",
      "61   [      62.      ]                          Mudhalvan  [\\n, [8.1], \\n]   \n",
      "62   [      63.      ]             Dhuruvangal Pathinaaru  [\\n, [8.1], \\n]   \n",
      "63   [      64.      ]                              Black  [\\n, [8.1], \\n]   \n",
      "64   [      65.      ]                         Chhichhore  [\\n, [8.1], \\n]   \n",
      "65   [      66.      ]                           Spadikam  [\\n, [8.1], \\n]   \n",
      "66   [      67.      ]             Swades: We, the People  [\\n, [8.1], \\n]   \n",
      "67   [      68.      ]                     Chak De! India  [\\n, [8.1], \\n]   \n",
      "68   [      69.      ]             Jo Jeeta Wohi Sikandar  [\\n, [8.1], \\n]   \n",
      "69   [      70.      ]                       Pudhu Pettai  [\\n, [8.1], \\n]   \n",
      "70   [      71.      ]                          Papanasam  [\\n, [8.1], \\n]   \n",
      "71   [      72.      ]                             Pyaasa  [\\n, [8.1], \\n]   \n",
      "72   [      73.      ]                      Soodhu Kavvum  [\\n, [8.1], \\n]   \n",
      "73   [      74.      ]                                 PK  [\\n, [8.0], \\n]   \n",
      "74   [      75.      ]                Munna Bhai M.B.B.S.  [\\n, [8.0], \\n]   \n",
      "75   [      76.      ]                            Mandela  [\\n, [8.0], \\n]   \n",
      "76   [      77.      ]                         Article 15  [\\n, [8.0], \\n]   \n",
      "77   [      78.      ]                              Queen  [\\n, [8.0], \\n]   \n",
      "78   [      79.      ]                             Talvar  [\\n, [8.0], \\n]   \n",
      "79   [      80.      ]           Uri: The Surgical Strike  [\\n, [8.0], \\n]   \n",
      "80   [      81.      ]                     Kaakkaa Muttai  [\\n, [8.0], \\n]   \n",
      "81   [      82.      ]                    OMG: Oh My God!  [\\n, [8.0], \\n]   \n",
      "82   [      83.      ]  Lagaan: Once Upon a Time in India  [\\n, [8.0], \\n]   \n",
      "83   [      84.      ]                        Jigarthanda  [\\n, [8.0], \\n]   \n",
      "84   [      85.      ]                          Sarfarosh  [\\n, [8.0], \\n]   \n",
      "85   [      86.      ]                              Udaan  [\\n, [8.0], \\n]   \n",
      "86   [      87.      ]                             Barfi!  [\\n, [8.0], \\n]   \n",
      "87   [      88.      ]           Theeran Adhigaaram Ondru  [\\n, [8.0], \\n]   \n",
      "88   [      89.      ]                             Sholay  [\\n, [8.0], \\n]   \n",
      "89   [      90.      ]                        Ustad Hotel  [\\n, [8.0], \\n]   \n",
      "90   [      91.      ]                         Hera Pheri  [\\n, [8.0], \\n]   \n",
      "91   [      92.      ]         The Legend of Bhagat Singh  [\\n, [8.0], \\n]   \n",
      "92   [      93.      ]                             Angoor  [\\n, [8.0], \\n]   \n",
      "93   [      94.      ]                    Rang De Basanti  [\\n, [8.0], \\n]   \n",
      "94   [      95.      ]                             Baasha  [\\n, [8.0], \\n]   \n",
      "95   [      96.      ]                             Masaan  [\\n, [8.0], \\n]   \n",
      "96   [      97.      ]                            Kahaani  [\\n, [8.0], \\n]   \n",
      "97   [      98.      ]        Baahubali 2: The Conclusion  [\\n, [8.0], \\n]   \n",
      "98   [      99.      ]                     Dil Chahta Hai  [\\n, [8.0], \\n]   \n",
      "99  [      100.      ]            Maheshinte Prathikaaram  [\\n, [8.0], \\n]   \n",
      "\n",
      "   Year Of Release  \n",
      "0         [(2021)]  \n",
      "1         [(2003)]  \n",
      "2         [(1979)]  \n",
      "3         [(1987)]  \n",
      "4         [(2018)]  \n",
      "5         [(2009)]  \n",
      "6         [(1959)]  \n",
      "7         [(1993)]  \n",
      "8         [(2004)]  \n",
      "9         [(2019)]  \n",
      "10        [(2018)]  \n",
      "11        [(2007)]  \n",
      "12        [(2021)]  \n",
      "13        [(2022)]  \n",
      "14        [(2020)]  \n",
      "15        [(2016)]  \n",
      "16        [(1989)]  \n",
      "17        [(2019)]  \n",
      "18        [(2019)]  \n",
      "19        [(1992)]  \n",
      "20        [(1955)]  \n",
      "21        [(2019)]  \n",
      "22        [(2018)]  \n",
      "23        [(2015)]  \n",
      "24        [(1991)]  \n",
      "25        [(2016)]  \n",
      "26        [(2021)]  \n",
      "27        [(2021)]  \n",
      "28        [(2021)]  \n",
      "29        [(2015)]  \n",
      "30        [(1956)]  \n",
      "31        [(2018)]  \n",
      "32        [(1983)]  \n",
      "33        [(2006)]  \n",
      "34        [(2013)]  \n",
      "35        [(1975)]  \n",
      "36        [(2018)]  \n",
      "37        [(2019)]  \n",
      "38        [(2005)]  \n",
      "39        [(2018)]  \n",
      "40        [(2019)]  \n",
      "41        [(2014)]  \n",
      "42        [(1998)]  \n",
      "43        [(2015)]  \n",
      "44        [(2018)]  \n",
      "45        [(1993)]  \n",
      "46        [(2013)]  \n",
      "47        [(2012)]  \n",
      "48        [(2016)]  \n",
      "49        [(2018)]  \n",
      "50        [(2015)]  \n",
      "51        [(2002)]  \n",
      "52        [(1965)]  \n",
      "53        [(2012)]  \n",
      "54        [(1988)]  \n",
      "55        [(1997)]  \n",
      "56        [(2016)]  \n",
      "57        [(2011)]  \n",
      "58        [(2012)]  \n",
      "59        [(2017)]  \n",
      "60        [(2018)]  \n",
      "61        [(1999)]  \n",
      "62        [(2016)]  \n",
      "63        [(2005)]  \n",
      "64        [(2019)]  \n",
      "65        [(1995)]  \n",
      "66        [(2004)]  \n",
      "67        [(2007)]  \n",
      "68        [(1992)]  \n",
      "69        [(2006)]  \n",
      "70        [(2015)]  \n",
      "71        [(1957)]  \n",
      "72        [(2013)]  \n",
      "73        [(2014)]  \n",
      "74        [(2003)]  \n",
      "75        [(2021)]  \n",
      "76        [(2019)]  \n",
      "77        [(2013)]  \n",
      "78        [(2015)]  \n",
      "79        [(2019)]  \n",
      "80        [(2014)]  \n",
      "81        [(2012)]  \n",
      "82        [(2001)]  \n",
      "83        [(2014)]  \n",
      "84        [(1999)]  \n",
      "85        [(2010)]  \n",
      "86        [(2012)]  \n",
      "87        [(2017)]  \n",
      "88        [(1975)]  \n",
      "89        [(2012)]  \n",
      "90        [(2000)]  \n",
      "91        [(2002)]  \n",
      "92        [(1982)]  \n",
      "93        [(2006)]  \n",
      "94        [(1995)]  \n",
      "95        [(2015)]  \n",
      "96        [(2012)]  \n",
      "97        [(2017)]  \n",
      "98        [(2001)]  \n",
      "99        [(2016)]  \n"
     ]
    }
   ],
   "source": [
    "# Recalling the function\n",
    "imdb_indian(url=\"https://www.imdb.com/india/top-rated-indian-movies/?sort=rk,asc&mode=simple&page=1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb2a219",
   "metadata": {},
   "source": [
    "Question 4:\n",
    "\n",
    "Write s python program to display list of respected former presidents of India(i.e. Name , Term of office)\n",
    "from https://presidentofindia.nic.in/former-presidents.htm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46aa5131",
   "metadata": {},
   "source": [
    "A: To start with web scraping we must first check with the legality and server permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1049d9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(url):                          # Defining function to check whether connection can be established and permissions\n",
    "    page= requests.get(url)              # Checking for the server to be accessible of the website to be scrapped\n",
    "    print(page,\"\\n\")                     # Display result\n",
    "    \n",
    "    if page.status_code==200:                        # Condition for accessibility\n",
    "        print (\"Server is accessible for Web Scrapping\",\"\\n\",\"\\n\")\n",
    "    else:\n",
    "        print(\"Server is not accessible for Web Scrapping\",\"\\n\",\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94c14a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]> \n",
      "\n",
      "Server is accessible for Web Scrapping \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recalling the function\n",
    "check(url=\" https://presidentofindia.nic.in/former-presidents.htm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b2b3efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Function\n",
    "def president(url):\n",
    "\n",
    "# Creating empty list\n",
    "    col1=[]\n",
    "    col2=[]\n",
    "            \n",
    "# Setting rows and columns for max result display\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_rows', None)\n",
    "\n",
    "# To establish connection with the required webpage\n",
    "    page= requests.get(url)\n",
    "    \n",
    "\n",
    "# Fetching contents of the webpage\n",
    "    parse=BeautifulSoup(page.content)\n",
    "        \n",
    "# Condition to fetch the desired content and saving the result in the specified list    \n",
    "    for i in parse.find_all('div', class_=\"presidentListing\"):\n",
    "        col1.append(i.contents)\n",
    "\n",
    "    table=pd.DataFrame(col1)\n",
    "    \n",
    "    name=table.loc[:,1:1]\n",
    "    terms=table.loc[:,3:3]\n",
    "    name=name.replace('\\n',\"\",regex=True)\n",
    "    terms=terms.replace('\\n',\"\",regex=True)\n",
    "    president=pd.DataFrame()\n",
    "    president=pd.concat([name,terms], axis=1)\n",
    "    president.reset_index()\n",
    "    print(president)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82c5ae1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                1  \\\n",
      "0             [Shri Pranab Mukherjee (1935-2020)]   \n",
      "1   [Smt Pratibha Devisingh Patil (birth - 1934)]   \n",
      "2            [DR. A.P.J. Abdul Kalam (1931-2015)]   \n",
      "3            [Shri K. R. Narayanan (1920 - 2005)]   \n",
      "4           [Dr Shankar Dayal Sharma (1918-1999)]   \n",
      "5               [Shri R Venkataraman (1910-2009)]   \n",
      "6                  [Giani Zail Singh (1916-1994)]   \n",
      "7         [Shri Neelam Sanjiva Reddy (1913-1996)]   \n",
      "8          [Dr. Fakhruddin Ali Ahmed (1905-1977)]   \n",
      "9      [Shri Varahagiri Venkata Giri (1894-1980)]   \n",
      "10                 [Dr. Zakir Husain (1897-1969)]   \n",
      "11     [Dr. Sarvepalli Radhakrishnan (1888-1975)]   \n",
      "12             [Dr. Rajendra Prasad (1884-1963) ]   \n",
      "\n",
      "                                                    3  \n",
      "0   [[Term of Office:],  25 July, 2012 to 25 July,...  \n",
      "1   [[Term of Office:],  25 July, 2007 to 25 July,...  \n",
      "2   [[Term of Office:],  25 July, 2002 to 25 July,...  \n",
      "3   [[Term of Office:],  25 July, 1997 to 25 July,...  \n",
      "4   [[Term of Office:],  25 July, 1992 to 25 July,...  \n",
      "5   [[Term of Office:],  25 July, 1987 to 25 July,...  \n",
      "6   [[Term of Office:],  25 July, 1982 to 25 July,...  \n",
      "7   [[Term of Office:],  25 July, 1977 to 25 July,...  \n",
      "8   [[Term of Office:],  24 August, 1974 to 11 Feb...  \n",
      "9   [[Term of Office:],  3 May, 1969 to 20 July, 1...  \n",
      "10  [[Term of Office:],  13 May, 1967 to 3 May, 1969]  \n",
      "11  [[Term of Office:],  13 May, 1962 to 13 May, 1...  \n",
      "12  [[Term of Office:],  26 January, 1950 to 13 Ma...  \n"
     ]
    }
   ],
   "source": [
    "president(url=\"https://presidentofindia.nic.in/former-presidents.htm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18bf8a9",
   "metadata": {},
   "source": [
    "Question 5:\n",
    "\n",
    "Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "c) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaf160d",
   "metadata": {},
   "source": [
    "A: To start with web scraping we must first check with the legality and server permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fb9784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(url):                          # Defining function to check whether connection can be established and permissions\n",
    "    page= requests.get(url)              # Checking for the server to be accessible of the website to be scrapped\n",
    "    print(page,\"\\n\")                     # Display result\n",
    "    \n",
    "    if page.status_code==200:                        # Condition for accessibility\n",
    "        print (\"Server is accessible for Web Scrapping\",\"\\n\",\"\\n\")\n",
    "    else:\n",
    "        print(\"Server is not accessible for Web Scrapping\",\"\\n\",\"\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d269ce58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]> \n",
      "\n",
      "Server is accessible for Web Scrapping \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recalling the function\n",
    "check(url=\"https://www.icc-cricket.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef763e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def icc_men_a(url1):                     #Defining function\n",
    "    # Setting rows and columns for max result display\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    \n",
    "# To establish connection with the required webpage\n",
    "    page1=requests.get(url1)\n",
    "    \n",
    "# Fetching contents of the webpage\n",
    "    soup1=BeautifulSoup(page1.content)\n",
    "\n",
    "# Creating empty list to store data\n",
    "    col_rank=[]\n",
    "    col_team=[]\n",
    "    col_matches=[]\n",
    "    col_points=[]\n",
    "    col_ratings=[]\n",
    "    col5=[]\n",
    "# Condition to fetch the Top Ten ODI Team desired content and saving the result in the specified list  \n",
    "    \n",
    "    for i in soup1.find_all('td',class_=\"rankings-block__banner--pos\"):\n",
    "        col_rank.append(i.text)\n",
    "    for i in soup1.find_all('td',class_=\"table-body__cell table-body__cell--position u-text-right\"):\n",
    "        col_rank.extend(i.contents)\n",
    "    \n",
    "    for i in soup1.find_all('span', class_=\"u-show-phablet\"):\n",
    "        col_team.append(i.text)\n",
    "    for i in soup1.find_all('span', class_=\"u-show-phablet\"):\n",
    "        col_team.extend(i.contents) \n",
    "    \n",
    "    for i in soup1.find_all('td', class_=\"rankings-block__banner--matches\"):\n",
    "        col_matches.append(i.text)\n",
    "   \n",
    "    for i in soup1.find_all('td', class_=\"rankings-block__banner--points\"):\n",
    "        col_points.append(i.text)\n",
    "    \n",
    "    for i in soup1.find_all('td', class_=\"table-body__cell u-center-text\"):\n",
    "        col5.append(i.text)\n",
    "\n",
    "    for i in soup1.find_all('td',class_=\"rankings-block__banner--rating u-text-right\"):\n",
    "        col_ratings.append(i.text)\n",
    "    for i in soup1.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "        col_ratings.extend(i.contents)  \n",
    "# storing data as they were extracted from the same classes\n",
    "    pts=col5[1:19:2]\n",
    "    mat=col5[0:19:2]\n",
    "    \n",
    "\n",
    "# Concatenating lists\n",
    "    col_matches= col_matches + mat\n",
    "    col_points= col_points + pts\n",
    "    \n",
    "# Storing only top 10 records and maintaining the same number of arrays\n",
    "    col_rank=col_rank[0:10]\n",
    "    col_team=col_team[0:10]\n",
    "    col_matches=col_matches[0:10]\n",
    "    col_ratings=col_ratings[0:10]\n",
    "    col_points=col_points[0:10]\n",
    "\n",
    "# Creating Data Frames\n",
    "    table1= pd.DataFrame({\"Rank\":col_rank, \"Team\":col_team,\"Matches\":col_matches,\"Points\":col_points,\"Ratings\":col_ratings })\n",
    "    \n",
    "# To remove \"\\n\" tags\n",
    "    table1=table1.replace('\\n','',regex=True)\n",
    "    \n",
    "# To drop index from being displayed\n",
    "    table1=table1.to_string(index=False, col_space=15,justify='center')\n",
    "    \n",
    "    \n",
    "# To display result\n",
    "    print(\"Top 10 ICC-Womens ODI Team are:\",\"\\n\",table1,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "641b1c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ICC-Womens ODI Team are: \n",
      "       Rank            Team          Matches          Points                               Ratings                          \n",
      "        1              NZ              12            1,505                                  125                            \n",
      "        2             ENG              22            2,756                                                              125\n",
      "        3             PAK              19            2,005                                                              106\n",
      "        4             IND              22            2,304                                                              105\n",
      "        5             AUS              23            2,325                                                              101\n",
      "        6              SA              19            1,872                                                               99\n",
      "        7             BAN              24            2,275                                                               95\n",
      "        8              SL              29            2,658                                                               92\n",
      "        9              WI              32            2,306                                                               72\n",
      "       10             AFG              18            1,238                                                               69 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "icc_men_a(url1=\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de1c240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def icc_men(url2,url3):                     #Defining function\n",
    "# Setting rows and columns for max result display\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_rows', None)\n",
    "\n",
    "\n",
    "# To establish connection with the required webpage\n",
    "    page2=requests.get(url2)\n",
    "    page3=requests.get(url3)\n",
    "\n",
    "# Fetching contents of the webpage\n",
    "    soup2=BeautifulSoup(page2.content)\n",
    "    soup3=BeautifulSoup(page3.content)\n",
    "# Creating empty list to store data\n",
    "    \n",
    "    col1=[]\n",
    "    col2=[]\n",
    "    col3=[]\n",
    "    col4=[]\n",
    "    col6=[]\n",
    "    col7=[]\n",
    "    col8=[]\n",
    "    col9=[]\n",
    "        \n",
    "# Condition to fetch the Top Ten ODI Batting Players Men desired content and saving the result in the specified list  \n",
    "    td_tag=soup2.find_all('td')\n",
    "    string=str(td_tag)\n",
    "    \n",
    "    for i in soup2.find_all('span',class_=\"rankings-block__pos-number\"):\n",
    "        col1.append(i.text)\n",
    "    for i in soup2.find_all('span',class_=\"rankings-table__pos-number\"):\n",
    "        col1.extend(i.contents)\n",
    "    \n",
    "    for i in soup2.find_all('div', class_=\"rankings-block__banner--name-large\"):\n",
    "        col2.append(i.text)\n",
    "    for i in soup2.find_all('td', class_=\"table-body__cell rankings-table__name name\"):\n",
    "        col2.extend(i.contents)\n",
    "    \n",
    "    for i in soup2.find_all('div', class_=\"rankings-block__banner--nationality\"):\n",
    "        col3.append(i.text)\n",
    "    for i in soup2.find_all('span', class_=\"table-body__logo-text\"):\n",
    "        col3.extend(i.contents)\n",
    "    \n",
    "    for i in soup2.find_all('div', class_=\"rankings-block__banner--rating\"):\n",
    "        col4.append(i.text)\n",
    "    for i in soup2.find_all('td', class_=\"table-body__cell rating\"):\n",
    "        col4.extend(i.contents)\n",
    "    \n",
    "        \n",
    "# Condition to fetch the Top Ten ODI Bowling Players Men desired content and saving the result in the specified list  \n",
    "    td_tag=soup3.find_all('')\n",
    "    string=str(td_tag)\n",
    "    \n",
    "    for i in soup3.find_all('span',class_=\"rankings-block__pos-number\"):\n",
    "        col6.append(i.text)\n",
    "    for i in soup3.find_all('span',class_=\"rankings-table__pos-number\"):\n",
    "        col6.extend(i.contents)\n",
    "    \n",
    "    for i in soup3.find_all('div', class_=\"rankings-block__banner--name-large\"):\n",
    "        col7.append(i.text)\n",
    "    for i in soup3.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "        col7.extend(i.contents)\n",
    "        \n",
    "    for i in soup3.find_all('div', class_=\"rankings-block__banner--nationality\"):\n",
    "        col8.append(i.text)\n",
    "    for i in soup3.find_all('span',class_=\"table-body__logo-text\"):\n",
    "        col8.extend(i.contents)\n",
    "    \n",
    "    for i in soup3.find_all('div', class_=\"rankings-block__banner--rating\"):\n",
    "        col9.append(i.text)\n",
    "    for i in soup3.find_all('td',class_=\"table-body__cell rating\"):\n",
    "        col9.extend(i.contents)\n",
    "\n",
    "# For batting data process \n",
    "\n",
    "    table=pd.DataFrame({\"Name\":col2})\n",
    "    table=table.drop_duplicates(subset=None)\n",
    "    table=table.drop(1,axis=0)\n",
    "    table=table.replace('\\n',regex=True)\n",
    "    new_col2=table.values.tolist()\n",
    "    \n",
    "# For bowling data process\n",
    "    table_b=pd.DataFrame({\"Name\":col7})\n",
    "    table_b=table_b.drop_duplicates(subset=None)\n",
    "    table_b=table_b.drop(1,axis=0)\n",
    "    table_b=table_b.replace('\\n',regex=True)\n",
    "    new_col7=table_b.values.tolist()\n",
    "    \n",
    "# Storing only top 10 records and maintaining the same number of arrays\n",
    "    col1=col1[0:10]\n",
    "    new_col2=new_col2[0:10]\n",
    "    col3=col3[0:10]\n",
    "    col4=col4[0:10]\n",
    "    \n",
    "    col6=col6[0:10]\n",
    "    new_col7=new_col7[0:10]\n",
    "    col8=col8[0:10]\n",
    "    col9=col9[0:10]\n",
    "\n",
    "\n",
    "# Creating Data Frames\n",
    "    table2= pd.DataFrame({\"Rank\":col1, \"Name\":new_col2,\"Team\":col3,\"Ratings\":col4 }) \n",
    "    table3= pd.DataFrame({\"Rank\":col6, \"Name\":new_col7,\"Team\":col8, \"Ratings\":col9 })\n",
    "\n",
    "# To remove \"\\n\" tags\n",
    "    table2=table2.replace('\\n','',regex=True)\n",
    "    table3=table3.replace('\\n','',regex=True)\n",
    "    \n",
    "# To drop index from being displayed\n",
    "    table2=table2.to_string(index=False, col_space=7,justify='center')\n",
    "    table3=table3.to_string(index=False, col_space=7,justify='center')\n",
    "    \n",
    "# To display result\n",
    "    print(\"Top 10 ICC-Womens ODI Batting Players are:\",\"\\n\",table2,\"\\n\")\n",
    "    print(\"Top 10 ICC-Womens ODI Bowling Players are:\",\"\\n\",table3,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35c2dc24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ICC-Womens ODI Batting Players are: \n",
      "                                  Rank                                             Name                     Team          Ratings\n",
      "                                             1                                      [Babar Azam] PAK                       892  \n",
      "                                     2                                           [[Imam-ul-Haq]]                     PAK   815  \n",
      "                                     3                                           [[Virat Kohli]]                     IND   811  \n",
      "                                     4                                          [[Rohit Sharma]]                     IND   791  \n",
      "                                     5                                       [[Quinton de Kock]]                      SA   789  \n",
      "                                     6                                           [[Ross Taylor]]                      NZ   775  \n",
      "                                     7                                 [[Rassie van der Dussen]]                      SA   769  \n",
      "                                     8                                        [[Jonny Bairstow]]                     ENG   752  \n",
      "                                     9                                          [[David Warner]]                     AUS   737  \n",
      "                                    10                                             [[Shai Hope]]                      WI   718   \n",
      "\n",
      "Top 10 ICC-Womens ODI Bowling Players are: \n",
      "                                  Rank                                          Name                  Team          Ratings\n",
      "                                             1                                [Trent Boult] NZ                       726  \n",
      "                                     2                                       [[Matt Henry]]                     NZ   683  \n",
      "                                     3                                   [[Shaheen Afridi]]                    PAK   681  \n",
      "                                     4                                     [[Chris Woakes]]                    ENG   680  \n",
      "                                     5                                   [[Jasprit Bumrah]]                    IND   679  \n",
      "                                     6                                   [[Josh Hazlewood]]                    AUS   679  \n",
      "                                     7                                 [[Mujeeb Ur Rahman]]                    AFG   676  \n",
      "                                     8                                     [[Mehedi Hasan]]                    BAN   661  \n",
      "                                     9                                    [[Mohammad Nabi]]                    AFG   657  \n",
      "                                    10                                  [[Shakib Al Hasan]]                    BAN   657   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "icc_men(url2=\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\",\n",
    "         url3=\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142ff8d5",
   "metadata": {},
   "source": [
    "Question 6:\n",
    "\n",
    "Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2fd726",
   "metadata": {},
   "source": [
    "A: To start with web scraping we must first check with the legality and server permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f9fc6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(url):                          # Defining function to check whether connection can be established and permissions\n",
    "    page= requests.get(url)              # Checking for the server to be accessible of the website to be scrapped\n",
    "    print(page,\"\\n\")                     # Display result\n",
    "    \n",
    "    if page.status_code==200:                        # Condition for accessibility\n",
    "        print (\"Server is accessible for Web Scrapping\",\"\\n\",\"\\n\")\n",
    "    else:\n",
    "        print(\"Server is not accessible for Web Scrapping\",\"\\n\",\"\\n\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd61805f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]> \n",
      "\n",
      "Server is accessible for Web Scrapping \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recalling the function\n",
    "check(url=\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd8f1544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def icc_women_a(url1):                     #Defining function\n",
    "    # Setting rows and columns for max result display\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    \n",
    "# To establish connection with the required webpage\n",
    "    page1=requests.get(url1)\n",
    "    \n",
    "# Fetching contents of the webpage\n",
    "    soup1=BeautifulSoup(page1.content)\n",
    "\n",
    "# Creating empty list to store data\n",
    "    col_rank=[]\n",
    "    col_team=[]\n",
    "    col_matches=[]\n",
    "    col_points=[]\n",
    "    col_ratings=[]\n",
    "    col5=[]\n",
    "# Condition to fetch the Top Ten ODI Team desired content and saving the result in the specified list  \n",
    "    \n",
    "    for i in soup1.find_all('td',class_=\"rankings-block__banner--pos\"):\n",
    "        col_rank.append(i.text)\n",
    "    for i in soup1.find_all('td',class_=\"table-body__cell table-body__cell--position u-text-right\"):\n",
    "        col_rank.extend(i.contents)\n",
    "    \n",
    "    for i in soup1.find_all('span', class_=\"u-show-phablet\"):\n",
    "        col_team.append(i.text)\n",
    "    for i in soup1.find_all('span', class_=\"u-show-phablet\"):\n",
    "        col_team.extend(i.contents) \n",
    "    \n",
    "    for i in soup1.find_all('td', class_=\"rankings-block__banner--matches\"):\n",
    "        col_matches.append(i.text)\n",
    "   \n",
    "    for i in soup1.find_all('td', class_=\"rankings-block__banner--points\"):\n",
    "        col_points.append(i.text)\n",
    "    \n",
    "    for i in soup1.find_all('td', class_=\"table-body__cell u-center-text\"):\n",
    "        col5.append(i.text)\n",
    "\n",
    "    for i in soup1.find_all('td',class_=\"rankings-block__banner--rating u-text-right\"):\n",
    "        col_ratings.append(i.text)\n",
    "    for i in soup1.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "        col_ratings.extend(i.contents)  \n",
    "# storing data as they were extracted from the same classes\n",
    "    pts=col5[1:19:2]\n",
    "    mat=col5[0:19:2]\n",
    "    \n",
    "\n",
    "# Concatenating lists\n",
    "    col_matches= col_matches + mat\n",
    "    col_points= col_points + pts\n",
    "    \n",
    "# Storing only top 10 records and maintaining the same number of arrays\n",
    "    col_rank=col_rank[0:10]\n",
    "    col_team=col_team[0:10]\n",
    "    col_matches=col_matches[0:10]\n",
    "    col_ratings=col_ratings[0:10]\n",
    "    col_points=col_points[0:10]\n",
    "\n",
    "# Creating Data Frames\n",
    "    table1= pd.DataFrame({\"Rank\":col_rank, \"Team\":col_team,\"Matches\":col_matches,\"Points\":col_points,\"Ratings\":col_ratings })\n",
    "    \n",
    "# To remove \"\\n\" tags\n",
    "    table1=table1.replace('\\n','',regex=True)\n",
    "    \n",
    "# To drop index from being displayed\n",
    "    table1=table1.to_string(index=False, col_space=15,justify='center')\n",
    "    \n",
    "    \n",
    "# To display result\n",
    "    print(\"Top 10 ICC-Womens ODI Team are:\",\"\\n\",table1,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "757abc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ICC-Womens ODI Team are: \n",
      "       Rank            Team          Matches          Points                               Ratings                          \n",
      "        1             AUS              29            4,837                                  167                            \n",
      "        2              SA              32            3,949                                                              123\n",
      "        3             ENG              30            3,531                                                              118\n",
      "        4             IND              29            2,889                                                              100\n",
      "        5              NZ              31            3,019                                                               97\n",
      "        6              WI              30            2,768                                                               92\n",
      "        7             BAN              12              930                                                               78\n",
      "        8             PAK              30            1,962                                                               65\n",
      "        9              SL               8              384                                                               48\n",
      "       10             IRE               8              351                                                               44 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "icc_women_a(url1=\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba67a447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def icc_women(url2,url3):                     #Defining function\n",
    "# Setting rows and columns for max result display\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_rows', None)\n",
    "\n",
    "\n",
    "# To establish connection with the required webpage\n",
    "    page2=requests.get(url2)\n",
    "    page3=requests.get(url3)\n",
    "\n",
    "# Fetching contents of the webpage\n",
    "    soup2=BeautifulSoup(page2.content)\n",
    "    soup3=BeautifulSoup(page3.content)\n",
    "# Creating empty list to store data\n",
    "    \n",
    "    col1=[]\n",
    "    col2=[]\n",
    "    col3=[]\n",
    "    col4=[]\n",
    "    col6=[]\n",
    "    col7=[]\n",
    "    col8=[]\n",
    "    col9=[]\n",
    "        \n",
    "# Condition to fetch the Top Ten ODI Batting Players Women desired content and saving the result in the specified list  \n",
    "    td_tag=soup2.find_all('td')\n",
    "    string=str(td_tag)\n",
    "    \n",
    "    for i in soup2.find_all('span',class_=\"rankings-block__pos-number\"):\n",
    "        col1.append(i.text)\n",
    "    for i in soup2.find_all('span',class_=\"rankings-table__pos-number\"):\n",
    "        col1.extend(i.contents)\n",
    "    \n",
    "    for i in soup2.find_all('div', class_=\"rankings-block__banner--name-large\"):\n",
    "        col2.append(i.text)\n",
    "    for i in soup2.find_all('td', class_=\"table-body__cell rankings-table__name name\"):\n",
    "        col2.extend(i.contents)\n",
    "    \n",
    "    for i in soup2.find_all('div', class_=\"rankings-block__banner--nationality\"):\n",
    "        col3.append(i.text)\n",
    "    for i in soup2.find_all('span', class_=\"table-body__logo-text\"):\n",
    "        col3.extend(i.contents)\n",
    "    \n",
    "    for i in soup2.find_all('div', class_=\"rankings-block__banner--rating\"):\n",
    "        col4.append(i.text)\n",
    "    for i in soup2.find_all('td', class_=\"table-body__cell rating\"):\n",
    "        col4.extend(i.contents)\n",
    "    \n",
    "        \n",
    "# Condition to fetch the Top Ten ODI Bowling Players Women desired content and saving the result in the specified list  \n",
    "    td_tag=soup3.find_all('td')\n",
    "    string=str(td_tag)\n",
    "    \n",
    "    for i in soup3.find_all('span',class_=\"rankings-block__pos-number\"):\n",
    "        col6.append(i.text)\n",
    "    for i in soup3.find_all('span',class_=\"rankings-table__pos-number\"):\n",
    "        col6.extend(i.contents)\n",
    "    \n",
    "    for i in soup3.find_all('div', class_=\"rankings-block__banner--name-large\"):\n",
    "        col7.append(i.text)\n",
    "    for i in soup3.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "        col7.extend(i.contents)\n",
    "        \n",
    "    for i in soup3.find_all('div', class_=\"rankings-block__banner--nationality\"):\n",
    "        col8.append(i.text)\n",
    "    for i in soup3.find_all('span',class_=\"table-body__logo-text\"):\n",
    "        col8.extend(i.contents)\n",
    "    \n",
    "    for i in soup3.find_all('div', class_=\"rankings-block__banner--rating\"):\n",
    "        col9.append(i.text)\n",
    "    for i in soup3.find_all('td',class_=\"table-body__cell rating\"):\n",
    "        col9.extend(i.contents)\n",
    "\n",
    "# For batting data process \n",
    "\n",
    "    table=pd.DataFrame({\"Name\":col2})\n",
    "    table=table.drop_duplicates(subset=None)\n",
    "    table=table.drop(1,axis=0)\n",
    "    table=table.replace('\\n',regex=True)\n",
    "    new_col2=table.values.tolist()\n",
    "    \n",
    "# For bowling data process\n",
    "    table_b=pd.DataFrame({\"Name\":col7})\n",
    "    table_b=table_b.drop_duplicates(subset=None)\n",
    "    table_b=table_b.drop(1,axis=0)\n",
    "    table_b=table_b.replace('\\n',regex=True)\n",
    "    new_col7=table_b.values.tolist()\n",
    "    \n",
    "# Storing only top 10 records and maintaining the same number of arrays\n",
    "    col1=col1[0:10]\n",
    "    new_col2=new_col2[0:10]\n",
    "    col3=col3[0:10]\n",
    "    col4=col4[0:10]\n",
    "    \n",
    "    col6=col6[0:10]\n",
    "    new_col7=new_col7[0:10]\n",
    "    col8=col8[0:10]\n",
    "    col9=col9[0:10]\n",
    "\n",
    "\n",
    "# Creating Data Frames\n",
    "    table2= pd.DataFrame({\"Rank\":col1, \"Name\":new_col2,\"Team\":col3,\"Ratings\":col4 }) \n",
    "    table3= pd.DataFrame({\"Rank\":col6, \"Name\":new_col7,\"Team\":col8, \"Ratings\":col9 })\n",
    "\n",
    "# To remove \"\\n\" tags\n",
    "    table2=table2.replace('\\n','',regex=True)\n",
    "    table3=table3.replace('\\n','',regex=True)\n",
    "    \n",
    "# To drop index from being displayed\n",
    "    table2=table2.to_string(index=False, col_space=7,justify='center')\n",
    "    table3=table3.to_string(index=False, col_space=7,justify='center')\n",
    "    \n",
    "# To display result\n",
    "    print(\"Top 10 ICC-Womens ODI Batting Players are:\",\"\\n\",table2,\"\\n\")\n",
    "    print(\"Top 10 ICC-Womens ODI Bowling Players are:\",\"\\n\",table3,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68d67756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ICC-Womens ODI Batting Players are: \n",
      "                                  Rank                                           Name                   Team          Ratings\n",
      "                                             1                                [Alyssa Healy] AUS                       785  \n",
      "                                     2                                    [[Natalie Sciver]]                     ENG   750  \n",
      "                                     3                                       [[Beth Mooney]]                     AUS   748  \n",
      "                                     4                                   [[Laura Wolvaardt]]                      SA   713  \n",
      "                                     5                                       [[Meg Lanning]]                     AUS   710  \n",
      "                                     6                                    [[Rachael Haynes]]                     AUS   701  \n",
      "                                     7                                 [[Amy Satterthwaite]]                      NZ   681  \n",
      "                                     8                                   [[Smriti Mandhana]]                     IND   669  \n",
      "                                     9                                    [[Tammy Beaumont]]                     ENG   659  \n",
      "                                    10                                      [[Ellyse Perry]]                     AUS   642   \n",
      "\n",
      "Top 10 ICC-Womens ODI Bowling Players are: \n",
      "                                  Rank                                          Name                  Team          Ratings\n",
      "                                             1                         [Sophie Ecclestone] ENG                       771  \n",
      "                                     2                                  [[Shabnim Ismail]]                      SA   755  \n",
      "                                     3                                   [[Jess Jonassen]]                     AUS   725  \n",
      "                                     4                                    [[Megan Schutt]]                     AUS   722  \n",
      "                                     5                                  [[Ayabonga Khaka]]                      SA   668  \n",
      "                                     6                                  [[Jhulan Goswami]]                     IND   663  \n",
      "                                     7                                  [[Marizanne Kapp]]                      SA   642  \n",
      "                                     8                                  [[Anya Shrubsole]]                     ENG   629  \n",
      "                                     9                                      [[Kate Cross]]                     ENG   617  \n",
      "                                    10                                 [[Hayley Matthews]]                      WI   612   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "icc_women(url2=\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\",\n",
    "         url3=\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/bowling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b135a44",
   "metadata": {},
   "source": [
    "Question 7:\n",
    "\n",
    "7) Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world :\n",
    "i) Headline\n",
    "ii) Time\n",
    "iii) News Link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b8ea0d",
   "metadata": {},
   "source": [
    "A: To start with web scraping we must first check with the legality and server permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "406ecf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(url,url2):                          # Defining function to check whether connection can be established and permissions\n",
    "    page= requests.get(url)              # Checking for the server to be accessible of the website to be scrapped\n",
    "    print(page,\"\\n\")                     # Display result\n",
    "    \n",
    "    if page.status_code==200:                        # Condition for accessibility\n",
    "        print (\"Server is accessible for Web Scrapping\",\"\\n\",\"\\n\")\n",
    "    else:\n",
    "        print(\"Server is not accessible for Web Scrapping\",\"\\n\",\"\\n\")\n",
    "        \n",
    "    page2=requests.get(url2)                  # To connect with the desired webpage\n",
    "    permission=BeautifulSoup(page2.content)   # To parse the permissions\n",
    "    print (permission)                        # Display permissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f035a165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]> \n",
      "\n",
      "Server is accessible for Web Scrapping \n",
      " \n",
      "\n",
      "<html><body><p>#\n",
      "# robots.txt\n",
      "#\n",
      "# This file is to prevent the crawling and indexing of certain parts\n",
      "# of your site by web crawlers and spiders run by sites like Yahoo!\n",
      "# and Google. By telling these \"robots\" where not to go on your site,\n",
      "# you save bandwidth and server resources.\n",
      "\n",
      "Sitemap: https://www.cnbc.com/sitemapAll.xml\n",
      "Sitemap: https://www.cnbc.com/sitemap_news.xml\n",
      "Sitemap: https://www.cnbc.com/sitemapvideoAll.xml\n",
      "Sitemap: https://www.cnbc.com/SitemapQuotes.xml\n",
      "Sitemap: https://www.cnbc.com/sitemapSelectAll.xml\n",
      "\n",
      "User-agent: googlebot\n",
      "Disallow: /*native-android-mobile\n",
      "Disallow: /*native-android-tablet\n",
      "Disallow: /*mobile-native\n",
      "Disallow: /preview/\n",
      "Disallow: /undefined/\n",
      "Disallow: /proplayer\n",
      "Disallow: /appchart/*\n",
      "Disallow: /search/\n",
      "\n",
      "User-agent: *\n",
      "Disallow: /preview/\n",
      "Disallow: /undefined/\n",
      "Disallow: /proplayer\n",
      "Disallow: /appchart/*\n",
      "Disallow: /search/\n",
      "</p></body></html>\n"
     ]
    }
   ],
   "source": [
    "# Recalling the function\n",
    "check(url=\"https://www.cnbc.com/world/?region=world\",\n",
    "     url2=\"https://www.cnbc.com/robots.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df36478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnbc(url):                                             # Defining function to get headings from wikipedia's main page\n",
    "    page= requests.get(url)                                     # for getting respnse and hitting wikipedia server\n",
    "    parse= BeautifulSoup(page.content)                       # to get contents of the webpage\n",
    "    col1=[]                                                 # Creating an empty list to store data\n",
    "    col2=[]\n",
    "    col3=[]\n",
    "    \n",
    "    \n",
    "    for i in parse.find_all('a', class_=\"LatestNews-headline\"):  # condition to get headings\n",
    "        col1.append(i.text)                                # storing headers in the empty list we had created\n",
    "    for i in parse.find_all('time', class_=\"LatestNews-timestamp\"):  # condition to get headings\n",
    "        col2.append(i.text)                                # storing headers in the empty list we had created\n",
    "    for i in parse.find_all('a', class_=\"LatestNews-headline\"):       # condition to get headings\n",
    "        col3.append(i['href'])                                # storing headers in the empty list we had created\n",
    "                                 # storing headers in the empty list we had created\n",
    "        \n",
    "    table= pd.DataFrame({\"Paper Title\":col1, \"Published Date\":col2,\"Paper URL\":col3})         # Creating a Data Frame or table\n",
    "    \n",
    "# To display result\n",
    "    print(table) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f68dae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Paper Title Published Date  \\\n",
      "0   FDA backs changing Covid booster shots to targ...     11 Min Ago   \n",
      "1   Ketanji Brown Jackson to be sworn in as Suprem...     15 Min Ago   \n",
      "2   We're using cash raised this week to buy more ...     21 Min Ago   \n",
      "3   Here's one favorite tech stock to buy, accordi...     27 Min Ago   \n",
      "4     Top 10 companies employees don't want to leave      59 Min Ago   \n",
      "5   A little more than half of investors see S&P a...     1 Hour Ago   \n",
      "6   Russia's Gazprom cancels dividend for the firs...     1 Hour Ago   \n",
      "7   GOP megadonors turn on Trump, look to DeSantis...    2 Hours Ago   \n",
      "8   Supreme Court limits EPA's authority to set cl...    2 Hours Ago   \n",
      "9   Bitcoin on track for its worst quarter in more...    2 Hours Ago   \n",
      "10  What it's like working for an abortion provide...    2 Hours Ago   \n",
      "11  Bed Bath & Beyond names new chief accounting o...    2 Hours Ago   \n",
      "12  Only 1% get a perfect score on this Social Sec...    2 Hours Ago   \n",
      "13  Biden calls on Congress to ease Senate rules t...    2 Hours Ago   \n",
      "14  Nikola tries again to win shareholder support ...    2 Hours Ago   \n",
      "15  The worst first half for stocks since 1970? It...    2 Hours Ago   \n",
      "16  3 way to stand out in a new job and impress yo...    2 Hours Ago   \n",
      "17  4 great ways to use your mental health days th...    3 Hours Ago   \n",
      "18  OPEC+ sticks with planned oil production hike ...    3 Hours Ago   \n",
      "19  What Cramer is watching Thursday — market terr...    3 Hours Ago   \n",
      "20  Overturning Roe v. Wade may have long-term fin...    3 Hours Ago   \n",
      "21  Jefferies downgrades Simon, says shopping mall...    3 Hours Ago   \n",
      "22  Fed’s preferred inflation measure rose 4.7% in...    3 Hours Ago   \n",
      "23  Thursday's biggest analyst calls: Tesla, Coinb...    3 Hours Ago   \n",
      "24  Comeback rally attracts big retail buying, esp...    3 Hours Ago   \n",
      "25  Raymond James says it's time to buy health car...    4 Hours Ago   \n",
      "26  Stocks making the biggest moves premarket: Wal...    4 Hours Ago   \n",
      "27  5 things to know before the stock market opens...    4 Hours Ago   \n",
      "28  Bath & Body Works can more than double after f...    5 Hours Ago   \n",
      "29  Walgreens profits squeezed as Covid vaccines w...    5 Hours Ago   \n",
      "\n",
      "                                            Paper URL  \n",
      "0   https://www.cnbc.com/2022/06/30/fda-backs-chan...  \n",
      "1   https://www.cnbc.com/2022/06/30/supreme-court-...  \n",
      "2   https://www.cnbc.com/2022/06/30/were-using-cas...  \n",
      "3   https://www.cnbc.com/2022/06/30/new-cnbc-surve...  \n",
      "4   https://www.cnbc.com/2022/06/30/top-10-compani...  \n",
      "5   https://www.cnbc.com/2022/06/30/investors-see-...  \n",
      "6   https://www.cnbc.com/2022/06/30/russias-gazpro...  \n",
      "7   https://www.cnbc.com/2022/06/30/gop-megadonors...  \n",
      "8   https://www.cnbc.com/2022/06/30/-supreme-court...  \n",
      "9   https://www.cnbc.com/2022/06/30/bitcoin-btc-on...  \n",
      "10  https://www.cnbc.com/2022/06/30/what-its-like-...  \n",
      "11  https://www.cnbc.com/2022/06/30/bed-bath-beyon...  \n",
      "12  https://www.cnbc.com/2022/06/30/most-people-fa...  \n",
      "13  https://www.cnbc.com/2022/06/30/biden-calls-on...  \n",
      "14  https://www.cnbc.com/2022/06/30/nikola-shareho...  \n",
      "15  https://www.cnbc.com/2022/06/30/the-worst-firs...  \n",
      "16  https://www.cnbc.com/2022/06/30/ibm-hr-chief-h...  \n",
      "17  https://www.cnbc.com/2022/06/30/4-great-ways-t...  \n",
      "18  https://www.cnbc.com/2022/06/30/opec-sticks-wi...  \n",
      "19  https://www.cnbc.com/2022/06/30/what-cramer-is...  \n",
      "20  https://www.cnbc.com/2022/06/30/overturning-ro...  \n",
      "21  https://www.cnbc.com/2022/06/30/jefferies-down...  \n",
      "22  https://www.cnbc.com/2022/06/30/feds-preferred...  \n",
      "23  https://www.cnbc.com/2022/06/30/thursdays-stre...  \n",
      "24  https://www.cnbc.com/2022/06/30/the-market-com...  \n",
      "25  https://www.cnbc.com/2022/06/30/raymond-james-...  \n",
      "26  https://www.cnbc.com/2022/06/30/stocks-making-...  \n",
      "27  https://www.cnbc.com/2022/06/30/5-things-to-kn...  \n",
      "28  https://www.cnbc.com/2022/06/30/bath-and-body-...  \n",
      "29  https://www.cnbc.com/2022/06/30/walgreens-wba-...  \n"
     ]
    }
   ],
   "source": [
    "cnbc(url=\"https://www.cnbc.com/world/?region=world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a579a5",
   "metadata": {},
   "source": [
    "Question 8:\n",
    "\n",
    "\n",
    "Write a python program to scrape the details of most downloaded articles from AI in last 90 days.\n",
    "https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "Scrape below mentioned details :\n",
    "i) Paper Title\n",
    "ii) Authors\n",
    "iii) Published Date\n",
    "iv) Paper URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27613a2b",
   "metadata": {},
   "source": [
    "A: To start with web scraping we must first check with the legality and server permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4bd87aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(url,url2):                          # Defining function to check whether connection can be established and permissions\n",
    "    page= requests.get(url)              # Checking for the server to be accessible of the website to be scrapped\n",
    "    print(page,\"\\n\")                     # Display result\n",
    "    \n",
    "    if page.status_code==200:                        # Condition for accessibility\n",
    "        print (\"Server is accessible for Web Scrapping\",\"\\n\",\"\\n\")\n",
    "    else:\n",
    "        print(\"Server is not accessible for Web Scrapping\",\"\\n\",\"\\n\")\n",
    "        \n",
    "    page2=requests.get(url2)                  # To connect with the desired webpage\n",
    "    permission=BeautifulSoup(page2.content)   # To parse the permissions\n",
    "    print (permission)                        # Display permissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4762766c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]> \n",
      "\n",
      "Server is accessible for Web Scrapping \n",
      " \n",
      "\n",
      "<html><body><p># Robots.txt file for https://www.elsevier.com\n",
      "# Do Not Delete This File\n",
      "\n",
      "User-agent: FAST Enterprise Crawler 6 / Scirus\n",
      "Disallow:\n",
      "\n",
      "User-agent: innosense/Nutch-1.0\n",
      "Disallow: /\n",
      "\n",
      "User-agent: Sogou web spider/4.0\n",
      "Disallow: /\n",
      "\n",
      "User-agent: Xenu Link Sleuth/1.3.8\n",
      "Disallow: /\n",
      "\n",
      "User-agent: discoverybot/2.0\n",
      "Disallow: /\n",
      "\n",
      "User-agent: YoudaoBot/1.0\n",
      "Disallow: /\n",
      "\n",
      "User-agent: Sogou web spider/3.0\n",
      "Disallow: /\n",
      "\n",
      "User-agent: *\n",
      "Disallow: /connect/archive\n",
      "Disallow: /about/press-releases/archive\n",
      "Disallow: /_dynamic-products/\n",
      "Disallow: /administration/\n",
      "Disallow: /_squiz-test/\n",
      "Disallow: /test-folder/\n",
      "Disallow: /ajax-content/\n",
      "Disallow: /fb-search/\n",
      "Disallow: /_Test folder/\n",
      "Disallow: /infermed-community/\n",
      "Disallow: /PII/\n",
      "Disallow: /gej-ng/\n",
      "Disallow: /cgi-bin/\n",
      "Disallow: /__returned/\n",
      "Disallow: /ctx/\n",
      "Disallow: /s/\n",
      "Disallow: /inca\n",
      "Disallow: /wps/find/\n",
      "Disallow: /wps/inca/\n",
      "Disallow: /wps/subject/\n",
      "Disallow: /wps/product/cws_home/\n",
      "Disallow: /wps/locate\n",
      "Disallow: /wps/product\n",
      "Disallow: /pub/\n",
      "Disallow: /IVP/\n",
      "Disallow: /febs/\n",
      "Disallow: /framework_librarians/\n",
      "Disallow: /framework_aboutus/\n",
      "Disallow: /elsevier-products/\n",
      "Disallow: */homepage/\n",
      "Disallow: */_dynamic/\n",
      "Disallow: */books-and-journals/book-companion/\n",
      "Disallow: */rd-solutions/industry-insights/pharma-and-life-sciences/ty\n",
      "Disallow: */about/our-business?a=568780\n",
      "Disallow: */clinical-solutions/contact/business-development-contact-us/drug-information-busdevform*\n",
      "Disallow: */search-results?*\n",
      "Disallow: /locate\n",
      "Disallow: /%20locate\n",
      "Disallow: /cas\n",
      "Disallow: /online-tools\n",
      "Disallow: /framework_products\n",
      "Disallow: /trends\n",
      "Disallow: /cdweb\n",
      "Disallow: /authored_subject_sections\n",
      "Disallow: /conferences\n",
      "Disallow: /jp\n",
      "Disallow: /jump\n",
      "Disallow: /catalogue\n",
      "Disallow: /pathway-studio\n",
      "Disallow: /framework_authors\n",
      "Disallow: /action\n",
      "Disallow: /catalog?*&amp;cat*\n",
      "Disallow: /zh-cn/test2\n",
      "Disallow: /promo/\n",
      "\n",
      "User-Agent: *\n",
      "Sitemap: https://www.elsevier.com/sitemaps/sitemap_index.xml\n",
      "</p></body></html>\n"
     ]
    }
   ],
   "source": [
    "# Recalling the function\n",
    "check(url=\"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\",\n",
    "     url2=\"https://www.elsevier.com/robots.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1baf3228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def journal(url):                                             # Defining function to get headings from wikipedia's main page\n",
    "    page= requests.get(url)                                     # for getting respnse and hitting wikipedia server\n",
    "    parse= BeautifulSoup(page.content)                       # to get contents of the webpage\n",
    "    col1=[]                                                 # Creating an empty list to store data\n",
    "    col2=[]\n",
    "    col3=[]\n",
    "    col4=[]\n",
    "    \n",
    "    for i in parse.find_all('h2', class_=\"sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR\"):  # condition to get headings\n",
    "        col1.append(i.text)                                # storing headers in the empty list we had created\n",
    "    for i in parse.find_all('span', class_=\"sc-1w3fpd7-0 pgLAT\"):  # condition to get headings\n",
    "        col2.append(i.text)                                # storing headers in the empty list we had created\n",
    "    for i in parse.find_all('span', class_=\"sc-1thf9ly-2 bKddwo\"):  # condition to get headings\n",
    "        col3.append(i.text)                                # storing headers in the empty list we had created\n",
    "    for i in parse.find_all('a', class_=\"sc-5smygv-0 nrDZj\"):  # condition to get headings\n",
    "        col4.append(i['href'])                                # storing headers in the empty list we had created\n",
    "        \n",
    "    table= pd.DataFrame({\"Paper Title\":col1,\"Authors\":col2, \"Published Date\":col3,\"Paper URL\":col4})         # Creating a Data Frame or table\n",
    "    \n",
    "# To display result\n",
    "    print(table) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dac528d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Paper Title  \\\n",
      "0                                    Reward is enough   \n",
      "1                           Making sense of raw input   \n",
      "2   Law and logic: A review from an argumentation ...   \n",
      "3              Creativity and artificial intelligence   \n",
      "4   Artificial cognition for social human–robot in...   \n",
      "5   Explanation in artificial intelligence: Insigh...   \n",
      "6                       Making sense of sensory input   \n",
      "7   Conflict-based search for optimal multi-agent ...   \n",
      "8   Between MDPs and semi-MDPs: A framework for te...   \n",
      "9   The Hanabi challenge: A new frontier for AI re...   \n",
      "10  Evaluating XAI: A comparison of rule-based and...   \n",
      "11           Argumentation in artificial intelligence   \n",
      "12  Algorithms for computing strategies in two-pla...   \n",
      "13      Multiple object tracking: A literature review   \n",
      "14  Selection of relevant features and examples in...   \n",
      "15  A survey of inverse reinforcement learning: Ch...   \n",
      "16  Explaining individual predictions when feature...   \n",
      "17  A review of possible effects of cognitive bias...   \n",
      "18  Integrating social power into the decision-mak...   \n",
      "19  “That's (not) the output I expected!” On the r...   \n",
      "20  Explaining black-box classifiers using post-ho...   \n",
      "21  Algorithm runtime prediction: Methods & evalua...   \n",
      "22              Wrappers for feature subset selection   \n",
      "23  Commonsense visual sensemaking for autonomous ...   \n",
      "24         Quantum computation, quantum theory and AI   \n",
      "\n",
      "                                              Authors  Published Date  \\\n",
      "0   Silver, David, Singh, Satinder, Precup, Doina,...    October 2021   \n",
      "1           Evans, Richard, Bošnjak, Matko and 5 more    October 2021   \n",
      "2                   Prakken, Henry, Sartor, Giovanni     October 2015   \n",
      "3                                 Boden, Margaret A.      August 1998   \n",
      "4     Lemaignan, Séverin, Warnier, Mathieu and 3 more       June 2017   \n",
      "5                                        Miller, Tim    February 2019   \n",
      "6   Evans, Richard, Hernández-Orallo, José and 3 more      April 2021   \n",
      "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   February 2015   \n",
      "8   Sutton, Richard S., Precup, Doina, Singh, Sati...     August 1999   \n",
      "9         Bard, Nolan, Foerster, Jakob N. and 13 more      March 2020   \n",
      "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   February 2021   \n",
      "11               Bench-Capon, T.J.M., Dunne, Paul E.     October 2007   \n",
      "12       Bošanský, Branislav, Lisý, Viliam and 3 more     August 2016   \n",
      "13             Luo, Wenhan, Xing, Junliang and 4 more      April 2021   \n",
      "14                      Blum, Avrim L., Langley, Pat    December 1997   \n",
      "15                   Arora, Saurabh, Doshi, Prashant      August 2021   \n",
      "16      Aas, Kjersti, Jullum, Martin, Løland, Anders   September 2021   \n",
      "17  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...       June 2021   \n",
      "18    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    December 2016   \n",
      "19                      Riveiro, Maria, Thill, Serge   September 2021   \n",
      "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        May 2021   \n",
      "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    January 2014   \n",
      "22                      Kohavi, Ron, John, George H.    December 1997   \n",
      "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    October 2021   \n",
      "24                                   Ying, Mingsheng    February 2010   \n",
      "\n",
      "                                            Paper URL  \n",
      "0   https://www.sciencedirect.com/science/article/...  \n",
      "1   https://www.sciencedirect.com/science/article/...  \n",
      "2   https://www.sciencedirect.com/science/article/...  \n",
      "3   https://www.sciencedirect.com/science/article/...  \n",
      "4   https://www.sciencedirect.com/science/article/...  \n",
      "5   https://www.sciencedirect.com/science/article/...  \n",
      "6   https://www.sciencedirect.com/science/article/...  \n",
      "7   https://www.sciencedirect.com/science/article/...  \n",
      "8   https://www.sciencedirect.com/science/article/...  \n",
      "9   https://www.sciencedirect.com/science/article/...  \n",
      "10  https://www.sciencedirect.com/science/article/...  \n",
      "11  https://www.sciencedirect.com/science/article/...  \n",
      "12  https://www.sciencedirect.com/science/article/...  \n",
      "13  https://www.sciencedirect.com/science/article/...  \n",
      "14  https://www.sciencedirect.com/science/article/...  \n",
      "15  https://www.sciencedirect.com/science/article/...  \n",
      "16  https://www.sciencedirect.com/science/article/...  \n",
      "17  https://www.sciencedirect.com/science/article/...  \n",
      "18  https://www.sciencedirect.com/science/article/...  \n",
      "19  https://www.sciencedirect.com/science/article/...  \n",
      "20  https://www.sciencedirect.com/science/article/...  \n",
      "21  https://www.sciencedirect.com/science/article/...  \n",
      "22  https://www.sciencedirect.com/science/article/...  \n",
      "23  https://www.sciencedirect.com/science/article/...  \n",
      "24  https://www.sciencedirect.com/science/article/...  \n"
     ]
    }
   ],
   "source": [
    "journal(url=\"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69ce1f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60da7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
